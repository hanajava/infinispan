2019-12-24 10:06:51,679 INFO  [org.jboss.modules] (main) JBoss Modules version 1.8.6.Final
2019-12-24 10:07:45,533 INFO  [org.jboss.msc] (main) JBoss MSC version 1.4.3.Final
2019-12-24 10:07:45,834 INFO  [org.jboss.threads] (main) JBoss Threads version 2.3.2.Final
2019-12-24 10:07:52,894 INFO  [org.jboss.as] (MSC service thread 1-2) WFLYSRV0049: Infinispan Server 9.4.17.Final (WildFly Core 6.0.2.Final) starting
2019-12-24 10:07:52,962 DEBUG [org.jboss.as.config] (MSC service thread 1-2) Configured system properties:
	[Standalone] = 
	awt.toolkit = sun.awt.X11.XToolkit
	file.encoding = UTF-8
	file.encoding.pkg = sun.io
	file.separator = /
	java.awt.graphicsenv = sun.awt.X11GraphicsEnvironment
	java.awt.printerjob = sun.print.PSPrinterJob
	java.class.path = /svc/infinispan/infinispan-server-9.4.17.Final/jboss-modules.jar
	java.class.version = 52.0
	java.endorsed.dirs = /usr/java/jdk1.8.0_202/jre/lib/endorsed
	java.ext.dirs = /usr/java/jdk1.8.0_202/jre/lib/ext:/usr/java/packages/lib/ext
	java.home = /usr/java/jdk1.8.0_202/jre
	java.io.tmpdir = /tmp
	java.library.path = /usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
	java.runtime.name = Java(TM) SE Runtime Environment
	java.runtime.version = 1.8.0_202-b08
	java.specification.name = Java Platform API Specification
	java.specification.vendor = Oracle Corporation
	java.specification.version = 1.8
	java.util.logging.manager = org.jboss.logmanager.LogManager
	java.vendor = Oracle Corporation
	java.vendor.url = http://java.oracle.com/
	java.vendor.url.bug = http://bugreport.sun.com/bugreport/
	java.version = 1.8.0_202
	java.vm.info = mixed mode
	java.vm.name = Java HotSpot(TM) 64-Bit Server VM
	java.vm.specification.name = Java Virtual Machine Specification
	java.vm.specification.vendor = Oracle Corporation
	java.vm.specification.version = 1.8
	java.vm.vendor = Oracle Corporation
	java.vm.version = 25.202-b08
	javax.management.builder.initial = org.jboss.as.jmx.PluggableMBeanServerBuilder
	jboss.bind.address = 192.168.110.141
	jboss.bind.address.management = 192.168.110.141
	jboss.home.dir = /svc/infinispan/infinispan-server-9.4.17.Final
	jboss.host.name = was01
	jboss.modules.dir = /svc/infinispan/infinispan-server-9.4.17.Final/modules
	jboss.node.name = hana11
	jboss.qualified.host.name = was01
	jboss.server.base.dir = /svc/infinispan/domains/hana11
	jboss.server.config.dir = /svc/infinispan/domains/hana11/configuration
	jboss.server.data.dir = /svc/infinispan/domains/hana11/data
	jboss.server.deploy.dir = /svc/infinispan/domains/hana11/data/content
	jboss.server.log.dir = /svc/infinispan/domains/hana11/logs
	jboss.server.name = was01
	jboss.server.persist.config = true
	jboss.server.temp.dir = /svc/infinispan/domains/hana11/tmp
	jboss.socket.binding.port-offset = 100
	line.separator = 

	logging.configuration = file:/svc/infinispan/domains/hana11/configuration/logging.properties
	module.path = /svc/infinispan/infinispan-server-9.4.17.Final/modules
	org.jboss.boot.log.file = /svc/infinispan/domains/hana11/logs/server.log
	org.jboss.resolver.warning = true
	os.arch = amd64
	os.name = Linux
	os.version = 3.10.0-862.el7.x86_64
	path.separator = :
	sun.arch.data.model = 64
	sun.boot.class.path = /usr/java/jdk1.8.0_202/jre/lib/resources.jar:/usr/java/jdk1.8.0_202/jre/lib/rt.jar:/usr/java/jdk1.8.0_202/jre/lib/sunrsasign.jar:/usr/java/jdk1.8.0_202/jre/lib/jsse.jar:/usr/java/jdk1.8.0_202/jre/lib/jce.jar:/usr/java/jdk1.8.0_202/jre/lib/charsets.jar:/usr/java/jdk1.8.0_202/jre/lib/jfr.jar:/usr/java/jdk1.8.0_202/jre/classes
	sun.boot.library.path = /usr/java/jdk1.8.0_202/jre/lib/amd64
	sun.cpu.endian = little
	sun.cpu.isalist = 
	sun.io.unicode.encoding = UnicodeLittle
	sun.java.command = /svc/infinispan/infinispan-server-9.4.17.Final/jboss-modules.jar -mp /svc/infinispan/infinispan-server-9.4.17.Final/modules org.jboss.as.standalone -Djboss.home.dir=/svc/infinispan/infinispan-server-9.4.17.Final -Djboss.server.base.dir=/svc/infinispan/domains/hana11 -Djboss.node.name=hana11 -c clustered.xml
	sun.java.launcher = SUN_STANDARD
	sun.jnu.encoding = UTF-8
	sun.management.compiler = HotSpot 64-Bit Tiered Compilers
	sun.os.patch.level = unknown
	user.country = US
	user.dir = /svc/infinispan/domains/hana11
	user.home = /home/jboss
	user.language = en
	user.name = jboss
	user.timezone = Asia/Seoul
2019-12-24 10:07:53,090 DEBUG [org.jboss.as.config] (MSC service thread 1-2) VM Arguments: -D[Standalone] -verbose:gc -Xloggc:/svc/infinispan/domains/hana11/logs/gc.log -XX:+PrintGCDetails -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=3M -XX:-TraceClassUnloading -Xms128m -Xmx512m -Xss256k -Djboss.server.base.dir=/svc/infinispan/domains/hana11 -Djboss.server.config.dir=/svc/infinispan/domains/hana11/configuration -Djboss.server.log.dir=/svc/infinispan/domains/hana11/logs -Djboss.socket.binding.port-offset=100 -Djboss.bind.address=192.168.110.141 -Djboss.bind.address.management=192.168.110.141 -Dorg.jboss.boot.log.file=/svc/infinispan/domains/hana11/logs/server.log -Dlogging.configuration=file:/svc/infinispan/domains/hana11/configuration/logging.properties 
2019-12-24 10:10:24,128 INFO  [org.wildfly.security] (ServerService Thread Pool -- 14) ELY00001: WildFly Elytron version 1.6.0.Final
2019-12-24 10:13:03,761 INFO  [org.jboss.as.controller.management-deprecated] (Controller Boot Thread) WFLYCTL0028: Attribute 'security-realm' in the resource at address '/core-service=management/management-interface=http-interface' is deprecated, and may be removed in a future version. See the attribute description in the output of the read-resource-description operation to learn more about the deprecation.
2019-12-24 10:13:09,868 INFO  [org.jboss.as.controller.management-deprecated] (ServerService Thread Pool -- 30) WFLYCTL0028: Attribute 'default-stack' in the resource at address '/subsystem=datagrid-jgroups' is deprecated, and may be removed in a future version. See the attribute description in the output of the read-resource-description operation to learn more about the deprecation.
2019-12-24 10:13:20,235 INFO  [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0039: Creating http management service using socket-binding (management-http)
2019-12-24 10:13:22,491 INFO  [org.xnio] (MSC service thread 1-1) XNIO version 3.6.5.Final
2019-12-24 10:13:23,394 INFO  [org.xnio.nio] (MSC service thread 1-1) XNIO NIO Implementation Version 3.6.5.Final
2019-12-24 10:13:27,684 INFO  [org.jboss.as.clustering.infinispan] (ServerService Thread Pool -- 42) Activating Infinispan subsystem.
2019-12-24 10:13:31,589 INFO  [org.infinispan.server.jgroups] (ServerService Thread Pool -- 45) DGJGRP0001: Activating JGroups subsystem.
2019-12-24 10:13:35,398 WARN  [org.jboss.as.txn] (ServerService Thread Pool -- 58) WFLYTX0013: The node-identifier attribute on the /subsystem=transactions is set to the default value. This is a danger for environments running multiple servers. Please make sure the attribute value is unique.
2019-12-24 10:13:35,511 INFO  [org.jboss.as.naming] (ServerService Thread Pool -- 53) WFLYNAM0001: Activating Naming Subsystem
2019-12-24 10:13:36,772 INFO  [org.jboss.as.security] (ServerService Thread Pool -- 56) WFLYSEC0002: Activating Security Subsystem
2019-12-24 10:13:37,640 INFO  [org.jboss.remoting] (MSC service thread 1-3) JBoss Remoting version 5.0.8.Final
2019-12-24 10:13:37,501 INFO  [org.jboss.as.security] (MSC service thread 1-8) WFLYSEC0001: Current PicketBox version=5.0.3.Final
2019-12-24 10:13:37,671 INFO  [org.jboss.as.connector.subsystems.datasources] (ServerService Thread Pool -- 46) WFLYJCA0004: Deploying JDBC-compliant driver class org.h2.Driver (version 1.4)
2019-12-24 10:13:38,279 INFO  [org.jboss.as.connector] (MSC service thread 1-6) WFLYJCA0009: Starting JCA Subsystem (WildFly/IronJacamar 1.4.11.Final)
2019-12-24 10:13:38,868 INFO  [org.jboss.as.naming] (MSC service thread 1-4) WFLYNAM0003: Starting Naming Service
2019-12-24 10:13:38,870 INFO  [org.jboss.as.connector.deployers.jdbc] (MSC service thread 1-5) WFLYJCA0018: Started Driver service with driver-name = h2
2019-12-24 10:13:39,488 INFO  [org.jboss.as.connector.subsystems.datasources] (MSC service thread 1-2) WFLYJCA0010: Unbound data source [java:jboss/datasources/ExampleDS]
2019-12-24 10:13:42,835 INFO  [org.jboss.as.patching] (MSC service thread 1-5) WFLYPAT0050: Infinispan Server cumulative patch ID is: base, one-off patches include: none
2019-12-24 10:13:43,098 INFO  [org.jboss.as.server.deployment.scanner] (MSC service thread 1-1) WFLYDS0013: Started FileSystemDeploymentService for directory /svc/infinispan/domains/hana11/deployments
2019-12-24 10:13:43,098 WARN  [org.jboss.as.domain.management.security] (MSC service thread 1-4) WFLYDM0111: Keystore /svc/infinispan/domains/hana11/configuration/application.keystore not found, it will be auto generated on first use with a self signed certificate for host localhost
2019-12-24 10:13:43,529 INFO  [org.jboss.as.connector.subsystems.datasources] (MSC service thread 1-4) WFLYJCA0001: Bound data source [java:jboss/datasources/ExampleDS]
2019-12-24 10:14:10,664 INFO  [org.jboss.modules] (main) JBoss Modules version 1.8.6.Final
2019-12-24 10:14:11,325 INFO  [org.jboss.msc] (main) JBoss MSC version 1.4.3.Final
2019-12-24 10:14:11,344 INFO  [org.jboss.threads] (main) JBoss Threads version 2.3.2.Final
2019-12-24 10:14:11,544 INFO  [org.jboss.as] (MSC service thread 1-2) WFLYSRV0049: Infinispan Server 9.4.17.Final (WildFly Core 6.0.2.Final) starting
2019-12-24 10:14:11,546 DEBUG [org.jboss.as.config] (MSC service thread 1-2) Configured system properties:
	[Standalone] = 
	awt.toolkit = sun.awt.X11.XToolkit
	file.encoding = UTF-8
	file.encoding.pkg = sun.io
	file.separator = /
	java.awt.graphicsenv = sun.awt.X11GraphicsEnvironment
	java.awt.printerjob = sun.print.PSPrinterJob
	java.class.path = /svc/infinispan/infinispan-server-9.4.17.Final/jboss-modules.jar
	java.class.version = 52.0
	java.endorsed.dirs = /usr/java/jdk1.8.0_202/jre/lib/endorsed
	java.ext.dirs = /usr/java/jdk1.8.0_202/jre/lib/ext:/usr/java/packages/lib/ext
	java.home = /usr/java/jdk1.8.0_202/jre
	java.io.tmpdir = /tmp
	java.library.path = /usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
	java.runtime.name = Java(TM) SE Runtime Environment
	java.runtime.version = 1.8.0_202-b08
	java.specification.name = Java Platform API Specification
	java.specification.vendor = Oracle Corporation
	java.specification.version = 1.8
	java.util.logging.manager = org.jboss.logmanager.LogManager
	java.vendor = Oracle Corporation
	java.vendor.url = http://java.oracle.com/
	java.vendor.url.bug = http://bugreport.sun.com/bugreport/
	java.version = 1.8.0_202
	java.vm.info = mixed mode
	java.vm.name = Java HotSpot(TM) 64-Bit Server VM
	java.vm.specification.name = Java Virtual Machine Specification
	java.vm.specification.vendor = Oracle Corporation
	java.vm.specification.version = 1.8
	java.vm.vendor = Oracle Corporation
	java.vm.version = 25.202-b08
	javax.management.builder.initial = org.jboss.as.jmx.PluggableMBeanServerBuilder
	jboss.bind.address = 192.168.110.141
	jboss.bind.address.management = 192.168.110.141
	jboss.home.dir = /svc/infinispan/infinispan-server-9.4.17.Final
	jboss.host.name = was01
	jboss.modules.dir = /svc/infinispan/infinispan-server-9.4.17.Final/modules
	jboss.node.name = hana11
	jboss.qualified.host.name = was01
	jboss.server.base.dir = /svc/infinispan/domains/hana11
	jboss.server.config.dir = /svc/infinispan/domains/hana11/configuration
	jboss.server.data.dir = /svc/infinispan/domains/hana11/data
	jboss.server.deploy.dir = /svc/infinispan/domains/hana11/data/content
	jboss.server.log.dir = /svc/infinispan/domains/hana11/logs
	jboss.server.name = was01
	jboss.server.persist.config = true
	jboss.server.temp.dir = /svc/infinispan/domains/hana11/tmp
	jboss.socket.binding.port-offset = 100
	line.separator = 

	logging.configuration = file:/svc/infinispan/domains/hana11/configuration/logging.properties
	module.path = /svc/infinispan/infinispan-server-9.4.17.Final/modules
	org.jboss.boot.log.file = /svc/infinispan/domains/hana11/logs/server.log
	org.jboss.resolver.warning = true
	os.arch = amd64
	os.name = Linux
	os.version = 3.10.0-862.el7.x86_64
	path.separator = :
	sun.arch.data.model = 64
	sun.boot.class.path = /usr/java/jdk1.8.0_202/jre/lib/resources.jar:/usr/java/jdk1.8.0_202/jre/lib/rt.jar:/usr/java/jdk1.8.0_202/jre/lib/sunrsasign.jar:/usr/java/jdk1.8.0_202/jre/lib/jsse.jar:/usr/java/jdk1.8.0_202/jre/lib/jce.jar:/usr/java/jdk1.8.0_202/jre/lib/charsets.jar:/usr/java/jdk1.8.0_202/jre/lib/jfr.jar:/usr/java/jdk1.8.0_202/jre/classes
	sun.boot.library.path = /usr/java/jdk1.8.0_202/jre/lib/amd64
	sun.cpu.endian = little
	sun.cpu.isalist = 
	sun.io.unicode.encoding = UnicodeLittle
	sun.java.command = /svc/infinispan/infinispan-server-9.4.17.Final/jboss-modules.jar -mp /svc/infinispan/infinispan-server-9.4.17.Final/modules org.jboss.as.standalone -Djboss.home.dir=/svc/infinispan/infinispan-server-9.4.17.Final -Djboss.server.base.dir=/svc/infinispan/domains/hana11 -Djboss.node.name=hana11 -c clustered.xml
	sun.java.launcher = SUN_STANDARD
	sun.jnu.encoding = UTF-8
	sun.management.compiler = HotSpot 64-Bit Tiered Compilers
	sun.os.patch.level = unknown
	user.country = US
	user.dir = /svc/infinispan/domains/hana11
	user.home = /home/jboss
	user.language = en
	user.name = jboss
	user.timezone = Asia/Seoul
2019-12-24 10:14:11,547 DEBUG [org.jboss.as.config] (MSC service thread 1-2) VM Arguments: -D[Standalone] -verbose:gc -Xloggc:/svc/infinispan/domains/hana11/logs/gc.log -XX:+PrintGCDetails -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=3M -XX:-TraceClassUnloading -Xms128m -Xmx512m -Xss256k -Djboss.server.base.dir=/svc/infinispan/domains/hana11 -Djboss.server.config.dir=/svc/infinispan/domains/hana11/configuration -Djboss.server.log.dir=/svc/infinispan/domains/hana11/logs -Djboss.socket.binding.port-offset=100 -Djboss.bind.address=192.168.110.141 -Djboss.bind.address.management=192.168.110.141 -Dorg.jboss.boot.log.file=/svc/infinispan/domains/hana11/logs/server.log -Dlogging.configuration=file:/svc/infinispan/domains/hana11/configuration/logging.properties 
2019-12-24 10:14:12,865 INFO  [org.wildfly.security] (ServerService Thread Pool -- 13) ELY00001: WildFly Elytron version 1.6.0.Final
2019-12-24 10:14:13,961 INFO  [org.jboss.as.controller.management-deprecated] (Controller Boot Thread) WFLYCTL0028: Attribute 'security-realm' in the resource at address '/core-service=management/management-interface=http-interface' is deprecated, and may be removed in a future version. See the attribute description in the output of the read-resource-description operation to learn more about the deprecation.
2019-12-24 10:14:14,020 INFO  [org.jboss.as.controller.management-deprecated] (ServerService Thread Pool -- 10) WFLYCTL0028: Attribute 'default-stack' in the resource at address '/subsystem=datagrid-jgroups' is deprecated, and may be removed in a future version. See the attribute description in the output of the read-resource-description operation to learn more about the deprecation.
2019-12-24 10:14:14,366 INFO  [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0039: Creating http management service using socket-binding (management-http)
2019-12-24 10:14:14,413 INFO  [org.xnio] (MSC service thread 1-4) XNIO version 3.6.5.Final
2019-12-24 10:14:14,437 INFO  [org.xnio.nio] (MSC service thread 1-4) XNIO NIO Implementation Version 3.6.5.Final
2019-12-24 10:14:14,539 INFO  [org.jboss.as.clustering.infinispan] (ServerService Thread Pool -- 17) Activating Infinispan subsystem.
2019-12-24 10:14:14,628 INFO  [org.jboss.as.connector.subsystems.datasources] (ServerService Thread Pool -- 21) WFLYJCA0004: Deploying JDBC-compliant driver class org.h2.Driver (version 1.4)
2019-12-24 10:14:14,712 INFO  [org.jboss.as.security] (ServerService Thread Pool -- 30) WFLYSEC0002: Activating Security Subsystem
2019-12-24 10:14:14,691 INFO  [org.jboss.as.naming] (ServerService Thread Pool -- 28) WFLYNAM0001: Activating Naming Subsystem
2019-12-24 10:14:14,686 WARN  [org.jboss.as.txn] (ServerService Thread Pool -- 31) WFLYTX0013: The node-identifier attribute on the /subsystem=transactions is set to the default value. This is a danger for environments running multiple servers. Please make sure the attribute value is unique.
2019-12-24 10:14:14,727 INFO  [org.infinispan.server.jgroups] (ServerService Thread Pool -- 20) DGJGRP0001: Activating JGroups subsystem.
2019-12-24 10:14:14,735 INFO  [org.jboss.as.security] (MSC service thread 1-6) WFLYSEC0001: Current PicketBox version=5.0.3.Final
2019-12-24 10:14:14,801 INFO  [org.jboss.as.connector] (MSC service thread 1-1) WFLYJCA0009: Starting JCA Subsystem (WildFly/IronJacamar 1.4.11.Final)
2019-12-24 10:14:14,884 INFO  [org.jboss.as.naming] (MSC service thread 1-5) WFLYNAM0003: Starting Naming Service
2019-12-24 10:14:14,894 INFO  [org.jboss.as.connector.deployers.jdbc] (MSC service thread 1-5) WFLYJCA0018: Started Driver service with driver-name = h2
2019-12-24 10:14:14,952 INFO  [org.jboss.remoting] (MSC service thread 1-1) JBoss Remoting version 5.0.8.Final
2019-12-24 10:14:15,186 INFO  [org.jboss.as.connector.subsystems.datasources] (MSC service thread 1-4) WFLYJCA0010: Unbound data source [java:jboss/datasources/ExampleDS]
2019-12-24 10:14:15,829 INFO  [org.jboss.as.patching] (MSC service thread 1-8) WFLYPAT0050: Infinispan Server cumulative patch ID is: base, one-off patches include: none
2019-12-24 10:14:15,888 WARN  [org.jboss.as.domain.management.security] (MSC service thread 1-1) WFLYDM0111: Keystore /svc/infinispan/domains/hana11/configuration/application.keystore not found, it will be auto generated on first use with a self signed certificate for host localhost
2019-12-24 10:14:15,896 INFO  [org.jboss.as.server.deployment.scanner] (MSC service thread 1-8) WFLYDS0013: Started FileSystemDeploymentService for directory /svc/infinispan/domains/hana11/deployments
2019-12-24 10:14:16,246 INFO  [org.jboss.as.connector.subsystems.datasources] (MSC service thread 1-4) WFLYJCA0001: Bound data source [java:jboss/datasources/ExampleDS]
2019-12-24 10:14:21,584 INFO  [org.jgroups.protocols.pbcast.GMS] (MSC service thread 1-7) hana11: no members discovered after 5006 ms: creating cluster as first member
2019-12-24 10:14:35,681 INFO  [org.infinispan.factories.GlobalComponentRegistry] (MSC service thread 1-6) ISPN000128: Infinispan version: Infinispan 'Infinity Minus ONE +2' 9.4.17.Final
2019-12-24 10:14:35,685 INFO  [org.infinispan.globalstate.impl.GlobalStateManagerImpl] (MSC service thread 1-6) ISPN000389: Loaded global state, version=9.4.17.Final timestamp=2019-12-23T02:00:59.976Z
2019-12-24 10:14:44,640 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (MSC service thread 1-6) ISPN000078: Starting JGroups channel clustered
2019-12-24 10:14:44,757 INFO  [org.infinispan.CLUSTER] (MSC service thread 1-6) ISPN000094: Received new cluster view for channel cluster: [hana11|0] (1) [hana11]
2019-12-24 10:14:44,775 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (MSC service thread 1-6) ISPN000079: Channel clustered local address is hana11, physical addresses are [192.168.110.141:55300]
2019-12-24 10:14:57,398 INFO  [org.jboss.as.clustering.infinispan] (MSC service thread 1-6) DGISPN0023: Started clustered cache container
2019-12-24 10:15:03,528 INFO  [org.jboss.as.clustering.infinispan] (MSC service thread 1-3) DGISPN0001: Started repl cache from clustered container
2019-12-24 10:15:03,650 INFO  [org.jboss.as.clustering.infinispan] (MSC service thread 1-8) DGISPN0001: Started HANA_CACHE cache from clustered container
2019-12-24 10:15:03,732 INFO  [org.jboss.as.clustering.infinispan] (MSC service thread 1-6) DGISPN0001: Started default cache from clustered container
2019-12-24 10:15:03,742 INFO  [org.infinispan.server.endpoint] (MSC service thread 1-3) DGENDPT10000: HotRodServer starting
2019-12-24 10:15:03,882 INFO  [org.infinispan.server.endpoint] (MSC service thread 1-3) DGENDPT10001: HotRodServer listening on 192.168.110.141:11322
2019-12-24 10:15:04,140 INFO  [org.infinispan.server.endpoint] (MSC service thread 1-4) DGENDPT10000:  starting
2019-12-24 10:15:11,931 INFO  [org.infinispan.server.endpoint] (MSC service thread 1-4) DGENDPT10002:  listening on 192.168.110.141:8180 (mapped to rest)
2019-12-24 10:15:14,433 INFO  [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0212: Resuming server
2019-12-24 10:15:14,435 INFO  [org.jboss.as] (Controller Boot Thread) WFLYSRV0060: Http management interface listening on http://192.168.110.141:10090/management
2019-12-24 10:15:14,442 INFO  [org.jboss.as] (Controller Boot Thread) WFLYSRV0051: Admin console listening on http://192.168.110.141:10090
2019-12-24 10:15:14,443 INFO  [org.jboss.as] (Controller Boot Thread) WFLYSRV0025: Infinispan Server 9.4.17.Final (WildFly Core 6.0.2.Final) started in 64284ms - Started 229 of 277 services (134 services are lazy, passive or on-demand)
2019-12-24 10:15:15,760 INFO  [org.infinispan.CLUSTER] (jgroups-6,hana11) ISPN000094: Received new cluster view for channel cluster: [hana11|1] (2) [hana11, hana12]
2019-12-24 10:15:15,819 INFO  [org.infinispan.CLUSTER] (jgroups-6,hana11) ISPN100000: Node hana12 joined the cluster
2019-12-24 10:15:27,771 INFO  [org.infinispan.CLUSTER] (VERIFY_SUSPECT.TimerThread-11,hana11) ISPN000094: Received new cluster view for channel cluster: [hana11|2] (1) [hana11]
2019-12-24 10:15:27,771 INFO  [org.infinispan.CLUSTER] (VERIFY_SUSPECT.TimerThread-11,hana11) ISPN100001: Node hana12 left the cluster
2019-12-24 10:16:17,267 INFO  [org.infinispan.CLUSTER] (jgroups-12,hana11) ISPN000093: Received new, MERGED cluster view for channel cluster: MergeView::[hana11|3] (2) [hana11, hana12], 2 subgroups: [hana11|2] (1) [hana11], [hana11|1] (2) [hana11, hana12]
2019-12-24 10:16:17,297 INFO  [org.infinispan.CLUSTER] (jgroups-12,hana11) ISPN100000: Node hana12 joined the cluster
2019-12-24 10:16:17,362 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t2) [Context=___protobuf_metadata]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 2
2019-12-24 10:16:17,362 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t3) [Context=default]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 2
2019-12-24 10:16:17,364 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t1) [Context=___hotRodTopologyCache]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 2
2019-12-24 10:16:17,419 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t1) [Context=org.infinispan.CONFIG]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 2
2019-12-24 10:16:17,498 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t2) [Context=repl]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 2
2019-12-24 10:16:20,369 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t1) [Context=org.infinispan.CONFIG]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 3
2019-12-24 10:16:20,417 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t3) [Context=___script_cache]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 2
2019-12-24 10:16:20,434 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t3) [Context=HANA_CACHE]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 2
2019-12-24 10:16:20,436 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t3) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 2
2019-12-24 10:16:20,684 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 4
2019-12-24 10:16:20,739 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 5
2019-12-24 10:16:20,759 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 6
2019-12-24 10:16:24,372 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 3
2019-12-24 10:16:25,399 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 4
2019-12-24 10:16:25,405 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 5
2019-12-24 10:16:25,412 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 6
2019-12-24 10:16:25,488 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 3
2019-12-24 10:16:26,630 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=repl]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 3
2019-12-24 10:16:27,145 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=HANA_CACHE]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 3
2019-12-24 10:16:27,455 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 4
2019-12-24 10:16:27,611 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=default]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 3
2019-12-24 10:16:28,248 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 5
2019-12-24 10:16:28,468 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 6
2019-12-24 10:16:28,605 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 4
2019-12-24 10:16:28,982 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=default]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 4
2019-12-24 10:16:29,086 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 5
2019-12-24 10:16:31,791 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=repl]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 4
2019-12-24 10:16:31,800 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=default]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 5
2019-12-24 10:16:31,884 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=HANA_CACHE]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 6
2019-12-24 10:16:31,928 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=repl]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 5
2019-12-24 10:16:32,000 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=repl]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 6
2019-12-24 10:16:32,000 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=default]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 6
2019-12-24 10:16:32,658 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___script_cache]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 3
2019-12-24 10:16:32,730 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 4
2019-12-24 10:16:32,788 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 5
2019-12-24 10:16:32,802 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___script_cache]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 6
2019-12-24 10:16:34,368 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___hotRodTopologyCache]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 3
2019-12-24 10:16:34,647 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 4
2019-12-24 10:16:34,663 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 5
2019-12-24 10:16:34,668 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___hotRodTopologyCache]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 6
2019-12-24 10:20:46,341 INFO  [org.infinispan.CLUSTER] (VERIFY_SUSPECT.TimerThread-27,hana11) ISPN000094: Received new cluster view for channel cluster: [hana11|4] (1) [hana11]
2019-12-24 10:20:46,433 INFO  [org.infinispan.CLUSTER] (VERIFY_SUSPECT.TimerThread-27,hana11) ISPN100001: Node hana12 left the cluster
2019-12-24 10:20:46,533 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___hotRodTopologyCache]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:20:46,572 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___hotRodTopologyCache]ISPN100008: Updating cache members list [hana11], topology id 7
2019-12-24 10:20:46,727 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=default]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:20:46,729 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=default]ISPN100008: Updating cache members list [hana11], topology id 7
2019-12-24 10:20:46,751 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___protobuf_metadata]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:20:46,752 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___protobuf_metadata]ISPN100008: Updating cache members list [hana11], topology id 7
2019-12-24 10:20:46,764 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=org.infinispan.CONFIG]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:20:46,821 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=org.infinispan.CONFIG]ISPN100008: Updating cache members list [hana11], topology id 7
2019-12-24 10:20:46,824 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=repl]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:20:46,826 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=repl]ISPN100008: Updating cache members list [hana11], topology id 7
2019-12-24 10:20:46,829 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___script_cache]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:20:46,831 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___script_cache]ISPN100008: Updating cache members list [hana11], topology id 7
2019-12-24 10:20:46,834 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=HANA_CACHE]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:20:46,835 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=HANA_CACHE]ISPN100008: Updating cache members list [hana11], topology id 7
2019-12-24 10:20:46,837 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:20:46,841 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100008: Updating cache members list [hana11], topology id 7
2019-12-24 10:21:34,355 INFO  [org.infinispan.CLUSTER] (jgroups-26,hana11) ISPN000093: Received new, MERGED cluster view for channel cluster: MergeView::[hana11|5] (2) [hana11, hana12], 2 subgroups: [hana11|3] (2) [hana11, hana12], [hana11|4] (1) [hana11]
2019-12-24 10:21:34,356 INFO  [org.infinispan.CLUSTER] (jgroups-26,hana11) ISPN100000: Node hana12 joined the cluster
2019-12-24 10:21:34,403 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t1) [Context=___hotRodTopologyCache]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 8
2019-12-24 10:21:34,403 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t4) [Context=default]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 8
2019-12-24 10:21:34,414 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t5) [Context=___protobuf_metadata]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 8
2019-12-24 10:21:34,442 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t5) [Context=___protobuf_metadata]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 9
2019-12-24 10:21:34,443 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t5) [Context=org.infinispan.CONFIG]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 8
2019-12-24 10:21:34,444 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t1) [Context=___hotRodTopologyCache]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 9
2019-12-24 10:21:34,445 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t5) [Context=org.infinispan.CONFIG]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 9
2019-12-24 10:21:34,446 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t5) [Context=repl]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 8
2019-12-24 10:21:34,448 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t1) [Context=___script_cache]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 8
2019-12-24 10:21:34,449 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t5) [Context=repl]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 9
2019-12-24 10:21:34,450 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t5) [Context=HANA_CACHE]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 8
2019-12-24 10:21:34,928 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t1) [Context=___script_cache]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 9
2019-12-24 10:21:34,928 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t4) [Context=default]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 9
2019-12-24 10:21:34,964 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t4) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 8
2019-12-24 10:21:34,966 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t4) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 9
2019-12-24 10:21:34,968 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t5) [Context=HANA_CACHE]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 9
2019-12-24 10:21:35,191 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 10
2019-12-24 10:21:35,200 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=repl]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 10
2019-12-24 10:21:35,207 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=repl]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 11
2019-12-24 10:21:35,187 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 10
2019-12-24 10:21:35,232 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=default]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 10
2019-12-24 10:21:35,232 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 10
2019-12-24 10:21:35,234 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t8) [Context=repl]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 12
2019-12-24 10:21:35,242 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t7) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 10
2019-12-24 10:21:35,245 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 10
2019-12-24 10:21:35,265 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 11
2019-12-24 10:21:35,267 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t8) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 10
2019-12-24 10:21:35,277 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 11
2019-12-24 10:21:35,277 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 11
2019-12-24 10:21:35,281 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t8) [Context=HANA_CACHE]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 12
2019-12-24 10:21:35,295 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t7) [Context=default]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 11
2019-12-24 10:21:35,300 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 11
2019-12-24 10:21:35,302 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 11
2019-12-24 10:21:35,303 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 12
2019-12-24 10:21:35,305 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t8) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 12
2019-12-24 10:21:35,314 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t8) [Context=default]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 12
2019-12-24 10:21:35,314 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___script_cache]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 12
2019-12-24 10:21:35,329 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t8) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 11
2019-12-24 10:21:35,353 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___hotRodTopologyCache]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 12
2019-12-24 10:21:35,366 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t8) [Context=___protobuf_metadata]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 12
2019-12-24 10:26:13,641 INFO  [org.infinispan.CLUSTER] (VERIFY_SUSPECT.TimerThread-33,hana11) ISPN000094: Received new cluster view for channel cluster: [hana11|6] (1) [hana11]
2019-12-24 10:26:13,643 INFO  [org.infinispan.CLUSTER] (VERIFY_SUSPECT.TimerThread-33,hana11) ISPN100001: Node hana12 left the cluster
2019-12-24 10:26:13,790 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___hotRodTopologyCache]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:26:13,797 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___hotRodTopologyCache]ISPN100008: Updating cache members list [hana11], topology id 13
2019-12-24 10:26:13,800 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=default]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:26:13,801 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=default]ISPN100008: Updating cache members list [hana11], topology id 13
2019-12-24 10:26:13,844 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___protobuf_metadata]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:26:13,866 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___protobuf_metadata]ISPN100008: Updating cache members list [hana11], topology id 13
2019-12-24 10:26:13,940 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=org.infinispan.CONFIG]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:26:13,942 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=org.infinispan.CONFIG]ISPN100008: Updating cache members list [hana11], topology id 13
2019-12-24 10:26:14,027 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=repl]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:26:14,126 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=repl]ISPN100008: Updating cache members list [hana11], topology id 13
2019-12-24 10:26:14,156 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___script_cache]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:26:14,237 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___script_cache]ISPN100008: Updating cache members list [hana11], topology id 13
2019-12-24 10:26:14,239 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=HANA_CACHE]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:26:14,240 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=HANA_CACHE]ISPN100008: Updating cache members list [hana11], topology id 13
2019-12-24 10:26:14,242 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:26:14,244 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100008: Updating cache members list [hana11], topology id 13
2019-12-24 10:27:03,174 INFO  [org.infinispan.CLUSTER] (jgroups-32,hana11) ISPN000093: Received new, MERGED cluster view for channel cluster: MergeView::[hana11|7] (2) [hana11, hana12], 2 subgroups: [hana11|5] (2) [hana11, hana12], [hana11|6] (1) [hana11]
2019-12-24 10:27:03,174 INFO  [org.infinispan.CLUSTER] (jgroups-32,hana11) ISPN100000: Node hana12 joined the cluster
2019-12-24 10:27:06,365 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t1) [Context=___hotRodTopologyCache]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 14
2019-12-24 10:27:06,371 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t1) [Context=___hotRodTopologyCache]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 15
2019-12-24 10:27:06,380 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t6) [Context=default]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 14
2019-12-24 10:27:06,385 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t7) [Context=___protobuf_metadata]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 14
2019-12-24 10:27:06,388 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t7) [Context=___protobuf_metadata]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 15
2019-12-24 10:27:06,389 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t1) [Context=org.infinispan.CONFIG]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 14
2019-12-24 10:27:06,391 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t7) [Context=repl]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 14
2019-12-24 10:27:06,393 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t1) [Context=org.infinispan.CONFIG]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 15
2019-12-24 10:27:06,395 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t1) [Context=___script_cache]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 14
2019-12-24 10:27:06,401 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t1) [Context=___script_cache]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 15
2019-12-24 10:27:06,394 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t7) [Context=repl]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 15
2019-12-24 10:27:06,406 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t6) [Context=default]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 15
2019-12-24 10:27:06,412 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t7) [Context=HANA_CACHE]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 14
2019-12-24 10:27:06,552 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t7) [Context=HANA_CACHE]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 15
2019-12-24 10:27:06,592 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t6) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 14
2019-12-24 10:27:06,635 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t6) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 15
2019-12-24 10:27:06,745 WARN  [org.jgroups.protocols.pbcast.GMS] (jgroups-36,hana11) hana11: not member of view [hana12|8]; discarding it
2019-12-24 10:27:17,713 INFO  [org.infinispan.CLUSTER] (VERIFY_SUSPECT.TimerThread-39,hana11) ISPN000094: Received new cluster view for channel cluster: [hana11|9] (1) [hana11]
2019-12-24 10:27:17,792 INFO  [org.infinispan.CLUSTER] (VERIFY_SUSPECT.TimerThread-39,hana11) ISPN100001: Node hana12 left the cluster
2019-12-24 10:27:18,021 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___hotRodTopologyCache]ISPN100008: Updating cache members list [hana11], topology id 16
2019-12-24 10:27:18,079 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___hotRodTopologyCache]ISPN100008: Updating cache members list [hana11], topology id 17
2019-12-24 10:27:18,081 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=default]ISPN100008: Updating cache members list [hana11], topology id 16
2019-12-24 10:27:18,085 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=default]ISPN100008: Updating cache members list [hana11], topology id 17
2019-12-24 10:27:18,093 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___protobuf_metadata]ISPN100008: Updating cache members list [hana11], topology id 16
2019-12-24 10:27:18,100 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___protobuf_metadata]ISPN100008: Updating cache members list [hana11], topology id 17
2019-12-24 10:27:18,115 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=org.infinispan.CONFIG]ISPN100008: Updating cache members list [hana11], topology id 16
2019-12-24 10:27:18,118 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=org.infinispan.CONFIG]ISPN100008: Updating cache members list [hana11], topology id 17
2019-12-24 10:27:18,129 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=repl]ISPN100008: Updating cache members list [hana11], topology id 16
2019-12-24 10:27:18,150 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=repl]ISPN100008: Updating cache members list [hana11], topology id 17
2019-12-24 10:27:18,152 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___script_cache]ISPN100008: Updating cache members list [hana11], topology id 16
2019-12-24 10:27:18,154 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___script_cache]ISPN100008: Updating cache members list [hana11], topology id 17
2019-12-24 10:27:18,187 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=HANA_CACHE]ISPN100008: Updating cache members list [hana11], topology id 16
2019-12-24 10:27:18,189 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=HANA_CACHE]ISPN100008: Updating cache members list [hana11], topology id 17
2019-12-24 10:27:18,193 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100008: Updating cache members list [hana11], topology id 16
2019-12-24 10:27:18,196 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100008: Updating cache members list [hana11], topology id 17
2019-12-24 10:28:19,869 INFO  [org.infinispan.CLUSTER] (jgroups-36,hana11) ISPN000094: Received new cluster view for channel cluster: [hana11|10] (2) [hana11, hana12]
2019-12-24 10:28:19,870 INFO  [org.infinispan.CLUSTER] (jgroups-36,hana11) ISPN100000: Node hana12 joined the cluster
2019-12-24 10:28:23,066 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CONFIG]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 18
2019-12-24 10:28:23,293 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 19
2019-12-24 10:28:23,317 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 20
2019-12-24 10:28:23,353 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CONFIG]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 21
2019-12-24 10:28:23,842 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 18
2019-12-24 10:28:23,910 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 19
2019-12-24 10:28:23,919 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 20
2019-12-24 10:28:23,941 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 21
2019-12-24 10:28:24,113 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___protobuf_metadata]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 18
2019-12-24 10:28:24,156 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 19
2019-12-24 10:28:24,191 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 20
2019-12-24 10:28:24,211 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___protobuf_metadata]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 21
2019-12-24 10:28:24,229 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=default]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 18
2019-12-24 10:28:24,229 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t9) [Context=repl]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 18
2019-12-24 10:28:24,255 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t9) [Context=HANA_CACHE]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 18
2019-12-24 10:28:24,334 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=repl]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 19
2019-12-24 10:28:24,340 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t9) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 19
2019-12-24 10:28:24,350 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t9) [Context=default]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 19
2019-12-24 10:28:24,355 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=repl]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 20
2019-12-24 10:28:24,356 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t9) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 20
2019-12-24 10:28:24,364 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t9) [Context=default]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 20
2019-12-24 10:28:24,364 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=repl]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 21
2019-12-24 10:28:24,367 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=HANA_CACHE]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 21
2019-12-24 10:28:24,376 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=default]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 21
2019-12-24 10:28:24,624 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___script_cache]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 18
2019-12-24 10:28:24,689 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 19
2019-12-24 10:28:24,695 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 20
2019-12-24 10:28:24,700 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___script_cache]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 21
2019-12-24 10:28:24,865 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___hotRodTopologyCache]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 18
2019-12-24 10:28:24,912 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 19
2019-12-24 10:28:24,919 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 20
2019-12-24 10:28:24,925 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___hotRodTopologyCache]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 21
2019-12-24 10:33:09,568 INFO  [org.infinispan.CLUSTER] (VERIFY_SUSPECT.TimerThread-43,hana11) ISPN000094: Received new cluster view for channel cluster: [hana11|11] (1) [hana11]
2019-12-24 10:33:09,569 INFO  [org.infinispan.CLUSTER] (VERIFY_SUSPECT.TimerThread-43,hana11) ISPN100001: Node hana12 left the cluster
2019-12-24 10:33:09,573 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___hotRodTopologyCache]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:33:09,575 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___hotRodTopologyCache]ISPN100008: Updating cache members list [hana11], topology id 22
2019-12-24 10:33:09,578 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=default]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:33:09,579 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=default]ISPN100008: Updating cache members list [hana11], topology id 22
2019-12-24 10:33:09,589 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___protobuf_metadata]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:33:09,590 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___protobuf_metadata]ISPN100008: Updating cache members list [hana11], topology id 22
2019-12-24 10:33:09,595 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=org.infinispan.CONFIG]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:33:09,615 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=org.infinispan.CONFIG]ISPN100008: Updating cache members list [hana11], topology id 22
2019-12-24 10:33:09,676 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=repl]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:33:09,677 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=repl]ISPN100008: Updating cache members list [hana11], topology id 22
2019-12-24 10:33:09,680 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___script_cache]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:33:09,682 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___script_cache]ISPN100008: Updating cache members list [hana11], topology id 22
2019-12-24 10:33:09,684 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=HANA_CACHE]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:33:09,685 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=HANA_CACHE]ISPN100008: Updating cache members list [hana11], topology id 22
2019-12-24 10:33:09,687 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana11, hana12]
2019-12-24 10:33:09,688 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100008: Updating cache members list [hana11], topology id 22
2019-12-24 10:36:29,121 INFO  [org.infinispan.CLUSTER] (jgroups-42,hana11) ISPN000094: Received new cluster view for channel cluster: [hana11|12] (2) [hana11, hana12]
2019-12-24 10:36:29,122 INFO  [org.infinispan.CLUSTER] (jgroups-42,hana11) ISPN100000: Node hana12 joined the cluster
2019-12-24 10:36:31,347 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=org.infinispan.CONFIG]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 23
2019-12-24 10:36:31,489 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 24
2019-12-24 10:36:31,515 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 25
2019-12-24 10:36:31,524 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=org.infinispan.CONFIG]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 26
2019-12-24 10:36:31,979 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 23
2019-12-24 10:36:32,050 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 24
2019-12-24 10:36:32,060 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 25
2019-12-24 10:36:32,070 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 26
2019-12-24 10:36:32,222 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___protobuf_metadata]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 23
2019-12-24 10:36:32,335 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 24
2019-12-24 10:36:32,355 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 25
2019-12-24 10:36:32,426 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=HANA_CACHE]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 23
2019-12-24 10:36:32,491 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) [Context=default]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 23
2019-12-24 10:36:32,524 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___protobuf_metadata]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 26
2019-12-24 10:36:32,526 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) [Context=repl]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 23
2019-12-24 10:36:32,672 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 24
2019-12-24 10:36:32,684 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t12) [Context=repl]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 24
2019-12-24 10:36:32,733 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 25
2019-12-24 10:36:32,746 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t12) [Context=default]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 24
2019-12-24 10:36:32,756 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t12) [Context=repl]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 25
2019-12-24 10:36:32,757 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=default]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 25
2019-12-24 10:36:32,759 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) [Context=HANA_CACHE]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 26
2019-12-24 10:36:32,797 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t12) [Context=default]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 26
2019-12-24 10:36:32,790 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=repl]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 26
2019-12-24 10:36:32,923 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t12) [Context=___script_cache]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 23
2019-12-24 10:36:32,970 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 24
2019-12-24 10:36:33,149 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 25
2019-12-24 10:36:33,174 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___script_cache]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 26
2019-12-24 10:36:33,290 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___hotRodTopologyCache]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 23
2019-12-24 10:36:33,348 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 24
2019-12-24 10:36:33,363 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 25
2019-12-24 10:36:33,373 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___hotRodTopologyCache]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 26
2019-12-24 10:53:27,853 WARN  [org.jgroups.protocols.pbcast.GMS] (jgroups-53,hana11) hana11: not member of view [hana12|13]; discarding it
2019-12-24 10:54:15,810 INFO  [org.infinispan.CLUSTER] (jgroups-51,hana11) ISPN000093: Received new, MERGED cluster view for channel cluster: MergeView::[hana11|14] (2) [hana11, hana12], 2 subgroups: [hana11|12] (2) [hana11, hana12], [hana12|13] (1) [hana12]
2019-12-24 10:54:15,947 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t6) [Context=___hotRodTopologyCache]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 29
2019-12-24 10:54:15,947 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t8) [Context=default]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 29
2019-12-24 10:54:15,947 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t9) [Context=___protobuf_metadata]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 29
2019-12-24 10:54:16,019 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t9) [Context=___protobuf_metadata]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 30
2019-12-24 10:54:16,019 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t8) [Context=default]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 30
2019-12-24 10:54:16,019 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t6) [Context=___hotRodTopologyCache]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 30
2019-12-24 10:54:16,070 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t8) [Context=org.infinispan.CONFIG]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 29
2019-12-24 10:54:16,071 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t9) [Context=repl]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 29
2019-12-24 10:54:16,101 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t8) [Context=org.infinispan.CONFIG]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 30
2019-12-24 10:54:16,121 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t6) [Context=___script_cache]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 29
2019-12-24 10:54:16,281 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t8) [Context=HANA_CACHE]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 29
2019-12-24 10:54:16,362 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t9) [Context=repl]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 30
2019-12-24 10:54:16,380 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t6) [Context=___script_cache]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 30
2019-12-24 10:54:16,412 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t8) [Context=HANA_CACHE]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 30
2019-12-24 10:54:16,413 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t8) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 29
2019-12-24 10:54:16,780 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t8) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 30
2019-12-24 10:54:16,720 WARN  [org.infinispan.expiration.impl.ClusterExpirationManager] (pool-10-thread-1) ISPN000026: Caught exception purging data container!: java.lang.IllegalArgumentException: Node hana11 is not a member
	at org.infinispan.distribution.ch.impl.DefaultConsistentHash.getPrimarySegmentsForOwner(DefaultConsistentHash.java:128)
	at org.infinispan.distribution.group.impl.PartitionerConsistentHash.getPrimarySegmentsForOwner(PartitionerConsistentHash.java:76)
	at org.infinispan.expiration.impl.ClusterExpirationManager.purgeInMemoryContents(ClusterExpirationManager.java:119)
	at org.infinispan.expiration.impl.ClusterExpirationManager.processExpiration(ClusterExpirationManager.java:94)
	at org.infinispan.expiration.impl.ExpirationManagerImpl$ScheduledTask.run(ExpirationManagerImpl.java:245)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-12-24 10:54:17,097 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 31
2019-12-24 10:54:17,256 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t14) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 32
2019-12-24 10:54:17,616 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 31
2019-12-24 10:54:17,714 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 31
2019-12-24 10:54:17,764 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 31
2019-12-24 10:54:17,778 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=default]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 31
2019-12-24 10:54:17,810 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=repl]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 31
2019-12-24 10:54:17,813 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t17) [Context=org.infinispan.CONFIG]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 33
2019-12-24 10:54:17,816 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 31
2019-12-24 10:54:17,818 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 31
2019-12-24 10:54:17,844 WARN  [org.jgroups.protocols.pbcast.GMS] (jgroups-51,hana11) hana11: failed to collect all ACKs (expected=1) for view [hana11|14] after 2000ms, missing 1 ACKs from (1) hana12
2019-12-24 10:54:17,844 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=default]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 32
2019-12-24 10:54:17,845 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t19) [Context=repl]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 32
2019-12-24 10:54:17,851 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t14) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 32
2019-12-24 10:54:17,852 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t20) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 32
2019-12-24 10:54:17,862 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t19) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 32
2019-12-24 10:54:17,862 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t20) [Context=___protobuf_metadata]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 33
2019-12-24 10:54:17,863 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t16) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 32
2019-12-24 10:54:17,865 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t15) [Context=repl]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 33
2019-12-24 10:54:17,865 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t18) [Context=default]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 33
2019-12-24 10:54:17,870 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 32
2019-12-24 10:54:17,871 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t14) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 33
2019-12-24 10:54:17,937 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t14) [Context=HANA_CACHE]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 33
2019-12-24 10:54:17,937 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___script_cache]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 33
2019-12-24 10:54:17,947 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___hotRodTopologyCache]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 33
2019-12-24 10:59:09,984 WARN  [org.jgroups.protocols.pbcast.GMS] (jgroups-64,hana11) hana11: not member of view [hana12|15]; discarding it
2019-12-24 10:59:47,619 ERROR [org.infinispan.interceptors.impl.InvocationContextInterceptor] (External Management Request Threads -- 1) ISPN000136: Error executing command SizeCommand on Cache 'repl', writing keys []: org.infinispan.util.concurrent.TimeoutException
	at org.infinispan.stream.impl.AbstractCacheStream.performOperationRehashAware(AbstractCacheStream.java:313)
	at org.infinispan.stream.impl.AbstractCacheStream.performOperation(AbstractCacheStream.java:230)
	at org.infinispan.stream.impl.DistributedCacheStream.count(DistributedCacheStream.java:445)
	at org.infinispan.commands.read.SizeCommand.perform(SizeCommand.java:45)
	at org.infinispan.commands.read.SizeCommand.perform(SizeCommand.java:20)
	at org.infinispan.interceptors.impl.CallInterceptor.visitCommand(CallInterceptor.java:29)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:56)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.interceptors.distribution.BaseDistributionInterceptor.visitSizeCommand(BaseDistributionInterceptor.java:121)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.statetransfer.StateTransferInterceptor.handleDefault(StateTransferInterceptor.java:352)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNextAndExceptionally(BaseAsyncInterceptor.java:123)
	at org.infinispan.interceptors.impl.InvocationContextInterceptor.visitCommand(InvocationContextInterceptor.java:90)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:56)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitCommand(DDAsyncInterceptor.java:50)
	at org.infinispan.interceptors.impl.AsyncInterceptorChainImpl.invoke(AsyncInterceptorChainImpl.java:248)
	at org.infinispan.cache.impl.CacheImpl.size(CacheImpl.java:491)
	at org.infinispan.cache.impl.CacheImpl.size(CacheImpl.java:486)
	at org.infinispan.cache.impl.AbstractDelegatingCache.size(AbstractDelegatingCache.java:373)
	at org.infinispan.cache.impl.AbstractDelegatingCache.size(AbstractDelegatingCache.java:373)
	at org.infinispan.cache.impl.AbstractDelegatingCache.size(AbstractDelegatingCache.java:373)
	at org.infinispan.stats.impl.ClusterCacheStatsImpl.updateStats(ClusterCacheStatsImpl.java:139)
	at org.infinispan.stats.impl.AbstractClusterStats.fetchClusterWideStatsIfNeeded(AbstractClusterStats.java:114)
	at org.infinispan.stats.impl.AbstractClusterStats.getStat(AbstractClusterStats.java:207)
	at org.infinispan.stats.impl.AbstractClusterStats.getStatAsLong(AbstractClusterStats.java:198)
	at org.infinispan.stats.impl.ClusterCacheStatsImpl.getHits(ClusterCacheStatsImpl.java:221)
	at org.jboss.as.clustering.infinispan.subsystem.ClusteredCacheMetricsHandler.executeRuntimeStep(ClusteredCacheMetricsHandler.java:196)
	at org.jboss.as.controller.AbstractRuntimeOnlyHandler$1.execute(AbstractRuntimeOnlyHandler.java:59)
	at org.jboss.as.controller.AbstractOperationContext.executeStep(AbstractOperationContext.java:999)
	at org.jboss.as.controller.AbstractOperationContext.processStages(AbstractOperationContext.java:743)
	at org.jboss.as.controller.AbstractOperationContext.executeOperation(AbstractOperationContext.java:467)
	at org.jboss.as.controller.OperationContextImpl.executeOperation(OperationContextImpl.java:1411)
	at org.jboss.as.controller.ModelControllerImpl.internalExecute(ModelControllerImpl.java:423)
	at org.jboss.as.controller.ModelControllerImpl.lambda$execute$1(ModelControllerImpl.java:243)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:265)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:231)
	at org.jboss.as.controller.ModelControllerImpl.execute(ModelControllerImpl.java:243)
	at org.jboss.as.domain.http.server.DomainApiHandler.handleRequest(DomainApiHandler.java:212)
	at io.undertow.server.handlers.encoding.EncodingHandler.handleRequest(EncodingHandler.java:72)
	at org.jboss.as.domain.http.server.DomainApiCheckHandler.handleRequest(DomainApiCheckHandler.java:93)
	at org.jboss.as.domain.http.server.security.ElytronIdentityHandler.lambda$handleRequest$0(ElytronIdentityHandler.java:62)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:289)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:246)
	at org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:254)
	at org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:225)
	at org.jboss.as.domain.http.server.security.ElytronIdentityHandler.handleRequest(ElytronIdentityHandler.java:61)
	at io.undertow.server.handlers.BlockingHandler.handleRequest(BlockingHandler.java:56)
	at io.undertow.server.Connectors.executeRootHandler(Connectors.java:360)
	at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830)
	at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)
	at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:1985)
	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1487)
	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1378)
	at java.lang.Thread.run(Thread.java:748)
	at org.jboss.threads.JBossThread.run(JBossThread.java:485)

2019-12-24 10:59:47,684 ERROR [org.infinispan.stats.impl.ClusterCacheStatsImpl] (External Management Request Threads -- 1) Could not execute cluster wide cache stats operation : org.infinispan.util.concurrent.TimeoutException
	at org.infinispan.interceptors.impl.AsyncInterceptorChainImpl.invoke(AsyncInterceptorChainImpl.java:259)
	at org.infinispan.cache.impl.CacheImpl.size(CacheImpl.java:491)
	at org.infinispan.cache.impl.CacheImpl.size(CacheImpl.java:486)
	at org.infinispan.cache.impl.AbstractDelegatingCache.size(AbstractDelegatingCache.java:373)
	at org.infinispan.cache.impl.AbstractDelegatingCache.size(AbstractDelegatingCache.java:373)
	at org.infinispan.cache.impl.AbstractDelegatingCache.size(AbstractDelegatingCache.java:373)
	at org.infinispan.stats.impl.ClusterCacheStatsImpl.updateStats(ClusterCacheStatsImpl.java:139)
	at org.infinispan.stats.impl.AbstractClusterStats.fetchClusterWideStatsIfNeeded(AbstractClusterStats.java:114)
	at org.infinispan.stats.impl.AbstractClusterStats.getStat(AbstractClusterStats.java:207)
	at org.infinispan.stats.impl.AbstractClusterStats.getStatAsLong(AbstractClusterStats.java:198)
	at org.infinispan.stats.impl.ClusterCacheStatsImpl.getHits(ClusterCacheStatsImpl.java:221)
	at org.jboss.as.clustering.infinispan.subsystem.ClusteredCacheMetricsHandler.executeRuntimeStep(ClusteredCacheMetricsHandler.java:196)
	at org.jboss.as.controller.AbstractRuntimeOnlyHandler$1.execute(AbstractRuntimeOnlyHandler.java:59)
	at org.jboss.as.controller.AbstractOperationContext.executeStep(AbstractOperationContext.java:999)
	at org.jboss.as.controller.AbstractOperationContext.processStages(AbstractOperationContext.java:743)
	at org.jboss.as.controller.AbstractOperationContext.executeOperation(AbstractOperationContext.java:467)
	at org.jboss.as.controller.OperationContextImpl.executeOperation(OperationContextImpl.java:1411)
	at org.jboss.as.controller.ModelControllerImpl.internalExecute(ModelControllerImpl.java:423)
	at org.jboss.as.controller.ModelControllerImpl.lambda$execute$1(ModelControllerImpl.java:243)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:265)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:231)
	at org.jboss.as.controller.ModelControllerImpl.execute(ModelControllerImpl.java:243)
	at org.jboss.as.domain.http.server.DomainApiHandler.handleRequest(DomainApiHandler.java:212)
	at io.undertow.server.handlers.encoding.EncodingHandler.handleRequest(EncodingHandler.java:72)
	at org.jboss.as.domain.http.server.DomainApiCheckHandler.handleRequest(DomainApiCheckHandler.java:93)
	at org.jboss.as.domain.http.server.security.ElytronIdentityHandler.lambda$handleRequest$0(ElytronIdentityHandler.java:62)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:289)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:246)
	at org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:254)
	at org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:225)
	at org.jboss.as.domain.http.server.security.ElytronIdentityHandler.handleRequest(ElytronIdentityHandler.java:61)
	at io.undertow.server.handlers.BlockingHandler.handleRequest(BlockingHandler.java:56)
	at io.undertow.server.Connectors.executeRootHandler(Connectors.java:360)
	at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830)
	at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)
	at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:1985)
	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1487)
	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1378)
	at java.lang.Thread.run(Thread.java:748)
	at org.jboss.threads.JBossThread.run(JBossThread.java:485)
Caused by: org.infinispan.util.concurrent.TimeoutException
	at org.infinispan.stream.impl.AbstractCacheStream.performOperationRehashAware(AbstractCacheStream.java:313)
	at org.infinispan.stream.impl.AbstractCacheStream.performOperation(AbstractCacheStream.java:230)
	at org.infinispan.stream.impl.DistributedCacheStream.count(DistributedCacheStream.java:445)
	at org.infinispan.commands.read.SizeCommand.perform(SizeCommand.java:45)
	at org.infinispan.commands.read.SizeCommand.perform(SizeCommand.java:20)
	at org.infinispan.interceptors.impl.CallInterceptor.visitCommand(CallInterceptor.java:29)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:56)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.interceptors.distribution.BaseDistributionInterceptor.visitSizeCommand(BaseDistributionInterceptor.java:121)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.statetransfer.StateTransferInterceptor.handleDefault(StateTransferInterceptor.java:352)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNextAndExceptionally(BaseAsyncInterceptor.java:123)
	at org.infinispan.interceptors.impl.InvocationContextInterceptor.visitCommand(InvocationContextInterceptor.java:90)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:56)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitCommand(DDAsyncInterceptor.java:50)
	at org.infinispan.interceptors.impl.AsyncInterceptorChainImpl.invoke(AsyncInterceptorChainImpl.java:248)
	... 39 more
	Suppressed: org.infinispan.util.logging.TraceException
		at org.infinispan.interceptors.impl.SimpleAsyncInvocationStage.get(SimpleAsyncInvocationStage.java:41)
		at org.infinispan.interceptors.impl.AsyncInterceptorChainImpl.invoke(AsyncInterceptorChainImpl.java:250)
		... 39 more

2019-12-24 10:59:47,724 ERROR [org.jboss.as.controller.management-operation] (External Management Request Threads -- 1) WFLYCTL0013: Operation ("read-attribute") failed - address: ([
    ("subsystem" => "datagrid-infinispan"),
    ("cache-container" => "clustered"),
    ("replicated-cache" => "repl")
]): org.infinispan.commons.CacheException: Could not execute cluster wide cache stats operation
	at org.infinispan.stats.impl.AbstractClusterStats.fetchClusterWideStatsIfNeeded(AbstractClusterStats.java:117)
	at org.infinispan.stats.impl.AbstractClusterStats.getStat(AbstractClusterStats.java:207)
	at org.infinispan.stats.impl.AbstractClusterStats.getStatAsLong(AbstractClusterStats.java:198)
	at org.infinispan.stats.impl.ClusterCacheStatsImpl.getHits(ClusterCacheStatsImpl.java:221)
	at org.jboss.as.clustering.infinispan.subsystem.ClusteredCacheMetricsHandler.executeRuntimeStep(ClusteredCacheMetricsHandler.java:196)
	at org.jboss.as.controller.AbstractRuntimeOnlyHandler$1.execute(AbstractRuntimeOnlyHandler.java:59)
	at org.jboss.as.controller.AbstractOperationContext.executeStep(AbstractOperationContext.java:999)
	at org.jboss.as.controller.AbstractOperationContext.processStages(AbstractOperationContext.java:743)
	at org.jboss.as.controller.AbstractOperationContext.executeOperation(AbstractOperationContext.java:467)
	at org.jboss.as.controller.OperationContextImpl.executeOperation(OperationContextImpl.java:1411)
	at org.jboss.as.controller.ModelControllerImpl.internalExecute(ModelControllerImpl.java:423)
	at org.jboss.as.controller.ModelControllerImpl.lambda$execute$1(ModelControllerImpl.java:243)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:265)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:231)
	at org.jboss.as.controller.ModelControllerImpl.execute(ModelControllerImpl.java:243)
	at org.jboss.as.domain.http.server.DomainApiHandler.handleRequest(DomainApiHandler.java:212)
	at io.undertow.server.handlers.encoding.EncodingHandler.handleRequest(EncodingHandler.java:72)
	at org.jboss.as.domain.http.server.DomainApiCheckHandler.handleRequest(DomainApiCheckHandler.java:93)
	at org.jboss.as.domain.http.server.security.ElytronIdentityHandler.lambda$handleRequest$0(ElytronIdentityHandler.java:62)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:289)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:246)
	at org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:254)
	at org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:225)
	at org.jboss.as.domain.http.server.security.ElytronIdentityHandler.handleRequest(ElytronIdentityHandler.java:61)
	at io.undertow.server.handlers.BlockingHandler.handleRequest(BlockingHandler.java:56)
	at io.undertow.server.Connectors.executeRootHandler(Connectors.java:360)
	at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830)
	at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)
	at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:1985)
	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1487)
	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1378)
	at java.lang.Thread.run(Thread.java:748)
	at org.jboss.threads.JBossThread.run(JBossThread.java:485)
Caused by: org.infinispan.util.concurrent.TimeoutException
	at org.infinispan.interceptors.impl.AsyncInterceptorChainImpl.invoke(AsyncInterceptorChainImpl.java:259)
	at org.infinispan.cache.impl.CacheImpl.size(CacheImpl.java:491)
	at org.infinispan.cache.impl.CacheImpl.size(CacheImpl.java:486)
	at org.infinispan.cache.impl.AbstractDelegatingCache.size(AbstractDelegatingCache.java:373)
	at org.infinispan.cache.impl.AbstractDelegatingCache.size(AbstractDelegatingCache.java:373)
	at org.infinispan.cache.impl.AbstractDelegatingCache.size(AbstractDelegatingCache.java:373)
	at org.infinispan.stats.impl.ClusterCacheStatsImpl.updateStats(ClusterCacheStatsImpl.java:139)
	at org.infinispan.stats.impl.AbstractClusterStats.fetchClusterWideStatsIfNeeded(AbstractClusterStats.java:114)
	... 32 more
Caused by: org.infinispan.util.concurrent.TimeoutException
	at org.infinispan.stream.impl.AbstractCacheStream.performOperationRehashAware(AbstractCacheStream.java:313)
	at org.infinispan.stream.impl.AbstractCacheStream.performOperation(AbstractCacheStream.java:230)
	at org.infinispan.stream.impl.DistributedCacheStream.count(DistributedCacheStream.java:445)
	at org.infinispan.commands.read.SizeCommand.perform(SizeCommand.java:45)
	at org.infinispan.commands.read.SizeCommand.perform(SizeCommand.java:20)
	at org.infinispan.interceptors.impl.CallInterceptor.visitCommand(CallInterceptor.java:29)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:56)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.interceptors.distribution.BaseDistributionInterceptor.visitSizeCommand(BaseDistributionInterceptor.java:121)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.statetransfer.StateTransferInterceptor.handleDefault(StateTransferInterceptor.java:352)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNextAndExceptionally(BaseAsyncInterceptor.java:123)
	at org.infinispan.interceptors.impl.InvocationContextInterceptor.visitCommand(InvocationContextInterceptor.java:90)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:56)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitCommand(DDAsyncInterceptor.java:50)
	at org.infinispan.interceptors.impl.AsyncInterceptorChainImpl.invoke(AsyncInterceptorChainImpl.java:248)
	... 39 more
	Suppressed: org.infinispan.util.logging.TraceException
		at org.infinispan.interceptors.impl.SimpleAsyncInvocationStage.get(SimpleAsyncInvocationStage.java:41)
		at org.infinispan.interceptors.impl.AsyncInterceptorChainImpl.invoke(AsyncInterceptorChainImpl.java:250)
		... 39 more

2019-12-24 10:59:58,006 INFO  [org.infinispan.CLUSTER] (jgroups-68,hana11) ISPN000093: Received new, MERGED cluster view for channel cluster: MergeView::[hana11|16] (2) [hana11, hana12], 2 subgroups: [hana11|14] (2) [hana11, hana12], [hana12|15] (1) [hana12]
2019-12-24 10:59:58,510 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t65) [Context=___hotRodTopologyCache]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 36
2019-12-24 10:59:58,519 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t67) [Context=default]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 36
2019-12-24 10:59:58,534 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t68) [Context=___protobuf_metadata]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 36
2019-12-24 10:59:58,535 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t65) [Context=___hotRodTopologyCache]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 37
2019-12-24 10:59:58,536 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t65) [Context=org.infinispan.CONFIG]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 36
2019-12-24 10:59:58,537 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t65) [Context=org.infinispan.CONFIG]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 37
2019-12-24 10:59:58,570 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t67) [Context=default]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 37
2019-12-24 10:59:58,620 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t69) [Context=repl]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 36
2019-12-24 10:59:58,625 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t69) [Context=repl]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 37
2019-12-24 10:59:58,627 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t69) [Context=___script_cache]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 36
2019-12-24 10:59:58,639 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t69) [Context=___script_cache]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 37
2019-12-24 10:59:58,679 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t68) [Context=___protobuf_metadata]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 37
2019-12-24 10:59:58,683 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t68) [Context=HANA_CACHE]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 36
2019-12-24 10:59:58,694 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t67) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 36
2019-12-24 10:59:58,699 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t68) [Context=HANA_CACHE]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 37
2019-12-24 10:59:58,722 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t67) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 37
2019-12-24 10:59:58,772 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=repl]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 38
2019-12-24 10:59:58,783 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 38
2019-12-24 10:59:58,805 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) [Context=repl]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 39
2019-12-24 10:59:58,820 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 38
2019-12-24 10:59:58,820 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 38
2019-12-24 10:59:58,820 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t23) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 39
2019-12-24 10:59:58,822 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 38
2019-12-24 10:59:58,822 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=default]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 38
2019-12-24 10:59:58,837 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 38
2019-12-24 10:59:58,860 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t24) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 39
2019-12-24 10:59:58,867 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t27) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 39
2019-12-24 10:59:58,869 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t29) [Context=default]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 39
2019-12-24 10:59:58,871 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 39
2019-12-24 10:59:58,877 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 39
2019-12-24 10:59:58,878 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) [Context=repl]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 40
2019-12-24 10:59:58,887 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t23) [Context=HANA_CACHE]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 40
2019-12-24 10:59:58,887 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 38
2019-12-24 10:59:58,888 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___protobuf_metadata]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 40
2019-12-24 10:59:58,893 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) [Context=org.infinispan.CONFIG]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 40
2019-12-24 10:59:58,894 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=default]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 40
2019-12-24 10:59:58,898 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 40
2019-12-24 10:59:58,908 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) [Context=___hotRodTopologyCache]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 40
2019-12-24 10:59:58,925 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t23) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 39
2019-12-24 10:59:58,942 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t23) [Context=___script_cache]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 40
2019-12-24 11:00:00,025 WARN  [org.jgroups.protocols.pbcast.GMS] (jgroups-68,hana11) hana11: failed to collect all ACKs (expected=1) for view [hana11|16] after 2000ms, missing 1 ACKs from (1) hana12
2019-12-24 11:00:04,359 ERROR [org.infinispan.interceptors.impl.InvocationContextInterceptor] (External Management Request Threads -- 3) ISPN000136: Error executing command SizeCommand on Cache 'HANA_CACHE', writing keys []: org.infinispan.util.concurrent.TimeoutException
	at org.infinispan.stream.impl.AbstractCacheStream.performOperationRehashAware(AbstractCacheStream.java:313)
	at org.infinispan.stream.impl.AbstractCacheStream.performOperation(AbstractCacheStream.java:230)
	at org.infinispan.stream.impl.DistributedCacheStream.count(DistributedCacheStream.java:445)
	at org.infinispan.commands.read.SizeCommand.perform(SizeCommand.java:45)
	at org.infinispan.commands.read.SizeCommand.perform(SizeCommand.java:20)
	at org.infinispan.interceptors.impl.CallInterceptor.visitCommand(CallInterceptor.java:29)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:56)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.interceptors.distribution.BaseDistributionInterceptor.visitSizeCommand(BaseDistributionInterceptor.java:121)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.statetransfer.StateTransferInterceptor.handleDefault(StateTransferInterceptor.java:352)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNextAndExceptionally(BaseAsyncInterceptor.java:123)
	at org.infinispan.interceptors.impl.InvocationContextInterceptor.visitCommand(InvocationContextInterceptor.java:90)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:56)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitCommand(DDAsyncInterceptor.java:50)
	at org.infinispan.interceptors.impl.AsyncInterceptorChainImpl.invoke(AsyncInterceptorChainImpl.java:248)
	at org.infinispan.cache.impl.CacheImpl.size(CacheImpl.java:491)
	at org.infinispan.cache.impl.CacheImpl.size(CacheImpl.java:486)
	at org.infinispan.cache.impl.AbstractDelegatingCache.size(AbstractDelegatingCache.java:373)
	at org.infinispan.stats.impl.ClusterCacheStatsImpl.updateStats(ClusterCacheStatsImpl.java:139)
	at org.infinispan.stats.impl.AbstractClusterStats.fetchClusterWideStatsIfNeeded(AbstractClusterStats.java:114)
	at org.infinispan.stats.impl.AbstractClusterStats.getStat(AbstractClusterStats.java:207)
	at org.infinispan.stats.impl.AbstractClusterStats.getStatAsLong(AbstractClusterStats.java:198)
	at org.infinispan.stats.impl.ClusterCacheStatsImpl.getHits(ClusterCacheStatsImpl.java:221)
	at org.jboss.as.clustering.infinispan.subsystem.ClusteredCacheMetricsHandler.executeRuntimeStep(ClusteredCacheMetricsHandler.java:196)
	at org.jboss.as.controller.AbstractRuntimeOnlyHandler$1.execute(AbstractRuntimeOnlyHandler.java:59)
	at org.jboss.as.controller.AbstractOperationContext.executeStep(AbstractOperationContext.java:999)
	at org.jboss.as.controller.AbstractOperationContext.processStages(AbstractOperationContext.java:743)
	at org.jboss.as.controller.AbstractOperationContext.executeOperation(AbstractOperationContext.java:467)
	at org.jboss.as.controller.OperationContextImpl.executeOperation(OperationContextImpl.java:1411)
	at org.jboss.as.controller.ModelControllerImpl.internalExecute(ModelControllerImpl.java:423)
	at org.jboss.as.controller.ModelControllerImpl.lambda$execute$1(ModelControllerImpl.java:243)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:265)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:231)
	at org.jboss.as.controller.ModelControllerImpl.execute(ModelControllerImpl.java:243)
	at org.jboss.as.domain.http.server.DomainApiHandler.handleRequest(DomainApiHandler.java:212)
	at io.undertow.server.handlers.encoding.EncodingHandler.handleRequest(EncodingHandler.java:72)
	at org.jboss.as.domain.http.server.DomainApiCheckHandler.handleRequest(DomainApiCheckHandler.java:93)
	at org.jboss.as.domain.http.server.security.ElytronIdentityHandler.lambda$handleRequest$0(ElytronIdentityHandler.java:62)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:289)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:246)
	at org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:254)
	at org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:225)
	at org.jboss.as.domain.http.server.security.ElytronIdentityHandler.handleRequest(ElytronIdentityHandler.java:61)
	at io.undertow.server.handlers.BlockingHandler.handleRequest(BlockingHandler.java:56)
	at io.undertow.server.Connectors.executeRootHandler(Connectors.java:360)
	at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830)
	at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)
	at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:1985)
	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1487)
	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1378)
	at java.lang.Thread.run(Thread.java:748)
	at org.jboss.threads.JBossThread.run(JBossThread.java:485)

2019-12-24 11:00:04,360 ERROR [org.infinispan.stats.impl.ClusterCacheStatsImpl] (External Management Request Threads -- 3) Could not execute cluster wide cache stats operation : org.infinispan.util.concurrent.TimeoutException
	at org.infinispan.interceptors.impl.AsyncInterceptorChainImpl.invoke(AsyncInterceptorChainImpl.java:259)
	at org.infinispan.cache.impl.CacheImpl.size(CacheImpl.java:491)
	at org.infinispan.cache.impl.CacheImpl.size(CacheImpl.java:486)
	at org.infinispan.cache.impl.AbstractDelegatingCache.size(AbstractDelegatingCache.java:373)
	at org.infinispan.stats.impl.ClusterCacheStatsImpl.updateStats(ClusterCacheStatsImpl.java:139)
	at org.infinispan.stats.impl.AbstractClusterStats.fetchClusterWideStatsIfNeeded(AbstractClusterStats.java:114)
	at org.infinispan.stats.impl.AbstractClusterStats.getStat(AbstractClusterStats.java:207)
	at org.infinispan.stats.impl.AbstractClusterStats.getStatAsLong(AbstractClusterStats.java:198)
	at org.infinispan.stats.impl.ClusterCacheStatsImpl.getHits(ClusterCacheStatsImpl.java:221)
	at org.jboss.as.clustering.infinispan.subsystem.ClusteredCacheMetricsHandler.executeRuntimeStep(ClusteredCacheMetricsHandler.java:196)
	at org.jboss.as.controller.AbstractRuntimeOnlyHandler$1.execute(AbstractRuntimeOnlyHandler.java:59)
	at org.jboss.as.controller.AbstractOperationContext.executeStep(AbstractOperationContext.java:999)
	at org.jboss.as.controller.AbstractOperationContext.processStages(AbstractOperationContext.java:743)
	at org.jboss.as.controller.AbstractOperationContext.executeOperation(AbstractOperationContext.java:467)
	at org.jboss.as.controller.OperationContextImpl.executeOperation(OperationContextImpl.java:1411)
	at org.jboss.as.controller.ModelControllerImpl.internalExecute(ModelControllerImpl.java:423)
	at org.jboss.as.controller.ModelControllerImpl.lambda$execute$1(ModelControllerImpl.java:243)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:265)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:231)
	at org.jboss.as.controller.ModelControllerImpl.execute(ModelControllerImpl.java:243)
	at org.jboss.as.domain.http.server.DomainApiHandler.handleRequest(DomainApiHandler.java:212)
	at io.undertow.server.handlers.encoding.EncodingHandler.handleRequest(EncodingHandler.java:72)
	at org.jboss.as.domain.http.server.DomainApiCheckHandler.handleRequest(DomainApiCheckHandler.java:93)
	at org.jboss.as.domain.http.server.security.ElytronIdentityHandler.lambda$handleRequest$0(ElytronIdentityHandler.java:62)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:289)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:246)
	at org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:254)
	at org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:225)
	at org.jboss.as.domain.http.server.security.ElytronIdentityHandler.handleRequest(ElytronIdentityHandler.java:61)
	at io.undertow.server.handlers.BlockingHandler.handleRequest(BlockingHandler.java:56)
	at io.undertow.server.Connectors.executeRootHandler(Connectors.java:360)
	at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830)
	at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)
	at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:1985)
	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1487)
	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1378)
	at java.lang.Thread.run(Thread.java:748)
	at org.jboss.threads.JBossThread.run(JBossThread.java:485)
Caused by: org.infinispan.util.concurrent.TimeoutException
	at org.infinispan.stream.impl.AbstractCacheStream.performOperationRehashAware(AbstractCacheStream.java:313)
	at org.infinispan.stream.impl.AbstractCacheStream.performOperation(AbstractCacheStream.java:230)
	at org.infinispan.stream.impl.DistributedCacheStream.count(DistributedCacheStream.java:445)
	at org.infinispan.commands.read.SizeCommand.perform(SizeCommand.java:45)
	at org.infinispan.commands.read.SizeCommand.perform(SizeCommand.java:20)
	at org.infinispan.interceptors.impl.CallInterceptor.visitCommand(CallInterceptor.java:29)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:56)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.interceptors.distribution.BaseDistributionInterceptor.visitSizeCommand(BaseDistributionInterceptor.java:121)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.statetransfer.StateTransferInterceptor.handleDefault(StateTransferInterceptor.java:352)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNextAndExceptionally(BaseAsyncInterceptor.java:123)
	at org.infinispan.interceptors.impl.InvocationContextInterceptor.visitCommand(InvocationContextInterceptor.java:90)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:56)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitCommand(DDAsyncInterceptor.java:50)
	at org.infinispan.interceptors.impl.AsyncInterceptorChainImpl.invoke(AsyncInterceptorChainImpl.java:248)
	... 37 more
	Suppressed: org.infinispan.util.logging.TraceException
		at org.infinispan.interceptors.impl.SimpleAsyncInvocationStage.get(SimpleAsyncInvocationStage.java:41)
		at org.infinispan.interceptors.impl.AsyncInterceptorChainImpl.invoke(AsyncInterceptorChainImpl.java:250)
		... 37 more

2019-12-24 11:00:04,360 ERROR [org.jboss.as.controller.management-operation] (External Management Request Threads -- 3) WFLYCTL0013: Operation ("read-attribute") failed - address: ([
    ("subsystem" => "datagrid-infinispan"),
    ("cache-container" => "clustered"),
    ("distributed-cache" => "HANA_CACHE")
]): org.infinispan.commons.CacheException: Could not execute cluster wide cache stats operation
	at org.infinispan.stats.impl.AbstractClusterStats.fetchClusterWideStatsIfNeeded(AbstractClusterStats.java:117)
	at org.infinispan.stats.impl.AbstractClusterStats.getStat(AbstractClusterStats.java:207)
	at org.infinispan.stats.impl.AbstractClusterStats.getStatAsLong(AbstractClusterStats.java:198)
	at org.infinispan.stats.impl.ClusterCacheStatsImpl.getHits(ClusterCacheStatsImpl.java:221)
	at org.jboss.as.clustering.infinispan.subsystem.ClusteredCacheMetricsHandler.executeRuntimeStep(ClusteredCacheMetricsHandler.java:196)
	at org.jboss.as.controller.AbstractRuntimeOnlyHandler$1.execute(AbstractRuntimeOnlyHandler.java:59)
	at org.jboss.as.controller.AbstractOperationContext.executeStep(AbstractOperationContext.java:999)
	at org.jboss.as.controller.AbstractOperationContext.processStages(AbstractOperationContext.java:743)
	at org.jboss.as.controller.AbstractOperationContext.executeOperation(AbstractOperationContext.java:467)
	at org.jboss.as.controller.OperationContextImpl.executeOperation(OperationContextImpl.java:1411)
	at org.jboss.as.controller.ModelControllerImpl.internalExecute(ModelControllerImpl.java:423)
	at org.jboss.as.controller.ModelControllerImpl.lambda$execute$1(ModelControllerImpl.java:243)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:265)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:231)
	at org.jboss.as.controller.ModelControllerImpl.execute(ModelControllerImpl.java:243)
	at org.jboss.as.domain.http.server.DomainApiHandler.handleRequest(DomainApiHandler.java:212)
	at io.undertow.server.handlers.encoding.EncodingHandler.handleRequest(EncodingHandler.java:72)
	at org.jboss.as.domain.http.server.DomainApiCheckHandler.handleRequest(DomainApiCheckHandler.java:93)
	at org.jboss.as.domain.http.server.security.ElytronIdentityHandler.lambda$handleRequest$0(ElytronIdentityHandler.java:62)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:289)
	at org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:246)
	at org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:254)
	at org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:225)
	at org.jboss.as.domain.http.server.security.ElytronIdentityHandler.handleRequest(ElytronIdentityHandler.java:61)
	at io.undertow.server.handlers.BlockingHandler.handleRequest(BlockingHandler.java:56)
	at io.undertow.server.Connectors.executeRootHandler(Connectors.java:360)
	at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830)
	at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)
	at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:1985)
	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1487)
	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1378)
	at java.lang.Thread.run(Thread.java:748)
	at org.jboss.threads.JBossThread.run(JBossThread.java:485)
Caused by: org.infinispan.util.concurrent.TimeoutException
	at org.infinispan.interceptors.impl.AsyncInterceptorChainImpl.invoke(AsyncInterceptorChainImpl.java:259)
	at org.infinispan.cache.impl.CacheImpl.size(CacheImpl.java:491)
	at org.infinispan.cache.impl.CacheImpl.size(CacheImpl.java:486)
	at org.infinispan.cache.impl.AbstractDelegatingCache.size(AbstractDelegatingCache.java:373)
	at org.infinispan.stats.impl.ClusterCacheStatsImpl.updateStats(ClusterCacheStatsImpl.java:139)
	at org.infinispan.stats.impl.AbstractClusterStats.fetchClusterWideStatsIfNeeded(AbstractClusterStats.java:114)
	... 32 more
Caused by: org.infinispan.util.concurrent.TimeoutException
	at org.infinispan.stream.impl.AbstractCacheStream.performOperationRehashAware(AbstractCacheStream.java:313)
	at org.infinispan.stream.impl.AbstractCacheStream.performOperation(AbstractCacheStream.java:230)
	at org.infinispan.stream.impl.DistributedCacheStream.count(DistributedCacheStream.java:445)
	at org.infinispan.commands.read.SizeCommand.perform(SizeCommand.java:45)
	at org.infinispan.commands.read.SizeCommand.perform(SizeCommand.java:20)
	at org.infinispan.interceptors.impl.CallInterceptor.visitCommand(CallInterceptor.java:29)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:56)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.interceptors.distribution.BaseDistributionInterceptor.visitSizeCommand(BaseDistributionInterceptor.java:121)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.statetransfer.StateTransferInterceptor.handleDefault(StateTransferInterceptor.java:352)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNextAndExceptionally(BaseAsyncInterceptor.java:123)
	at org.infinispan.interceptors.impl.InvocationContextInterceptor.visitCommand(InvocationContextInterceptor.java:90)
	at org.infinispan.interceptors.BaseAsyncInterceptor.invokeNext(BaseAsyncInterceptor.java:56)
	at org.infinispan.interceptors.DDAsyncInterceptor.handleDefault(DDAsyncInterceptor.java:54)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitSizeCommand(DDAsyncInterceptor.java:100)
	at org.infinispan.commands.read.SizeCommand.acceptVisitor(SizeCommand.java:35)
	at org.infinispan.interceptors.DDAsyncInterceptor.visitCommand(DDAsyncInterceptor.java:50)
	at org.infinispan.interceptors.impl.AsyncInterceptorChainImpl.invoke(AsyncInterceptorChainImpl.java:248)
	... 37 more
	Suppressed: org.infinispan.util.logging.TraceException
		at org.infinispan.interceptors.impl.SimpleAsyncInvocationStage.get(SimpleAsyncInvocationStage.java:41)
		at org.infinispan.interceptors.impl.AsyncInterceptorChainImpl.invoke(AsyncInterceptorChainImpl.java:250)
		... 37 more

2019-12-24 11:19:00,097 WARN  [org.jgroups.protocols.pbcast.GMS] (jgroups-95,hana11) hana11: not member of view [hana12|17]; discarding it
2019-12-24 11:19:58,211 INFO  [org.infinispan.CLUSTER] (jgroups-94,hana11) ISPN000093: Received new, MERGED cluster view for channel cluster: MergeView::[hana11|18] (2) [hana11, hana12], 2 subgroups: [hana11|16] (2) [hana11, hana12], [hana12|17] (1) [hana12]
2019-12-24 11:19:58,781 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t126) [Context=default]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 43
2019-12-24 11:19:58,781 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t117) [Context=___hotRodTopologyCache]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 43
2019-12-24 11:19:59,177 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t127) [Context=___protobuf_metadata]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 43
2019-12-24 11:19:59,286 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t126) [Context=default]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 44
2019-12-24 11:19:59,286 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t117) [Context=___hotRodTopologyCache]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 44
2019-12-24 11:19:59,303 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t117) [Context=repl]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 43
2019-12-24 11:19:59,287 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t126) [Context=org.infinispan.CONFIG]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 43
2019-12-24 11:19:59,705 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t127) [Context=___protobuf_metadata]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 44
2019-12-24 11:19:59,868 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t117) [Context=repl]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 44
2019-12-24 11:19:59,873 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t127) [Context=___script_cache]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 43
2019-12-24 11:19:59,930 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t127) [Context=___script_cache]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 44
2019-12-24 11:19:59,958 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t126) [Context=org.infinispan.CONFIG]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 44
2019-12-24 11:19:59,966 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t117) [Context=HANA_CACHE]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 43
2019-12-24 11:19:59,969 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t117) [Context=HANA_CACHE]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 44
2019-12-24 11:20:00,050 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t117) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 43
2019-12-24 11:20:00,072 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t117) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 44
2019-12-24 11:20:00,254 WARN  [org.jgroups.protocols.pbcast.GMS] (jgroups-94,hana11) hana11: failed to collect all ACKs (expected=1) for view [hana11|18] after 2000ms, missing 1 ACKs from (1) hana12
2019-12-24 11:20:00,573 WARN  [org.infinispan.expiration.impl.ClusterExpirationManager] (pool-10-thread-1) ISPN000026: Caught exception purging data container!: java.lang.IllegalArgumentException: Node hana11 is not a member
	at org.infinispan.distribution.ch.impl.DefaultConsistentHash.getPrimarySegmentsForOwner(DefaultConsistentHash.java:128)
	at org.infinispan.distribution.group.impl.PartitionerConsistentHash.getPrimarySegmentsForOwner(PartitionerConsistentHash.java:76)
	at org.infinispan.expiration.impl.ClusterExpirationManager.purgeInMemoryContents(ClusterExpirationManager.java:119)
	at org.infinispan.expiration.impl.ClusterExpirationManager.processExpiration(ClusterExpirationManager.java:94)
	at org.infinispan.expiration.impl.ExpirationManagerImpl$ScheduledTask.run(ExpirationManagerImpl.java:245)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-12-24 11:20:01,298 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t35) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 45
2019-12-24 11:20:01,953 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t35) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 46
2019-12-24 11:20:03,845 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 45
2019-12-24 11:20:05,370 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t34) [Context=HANA_CACHE]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 47
2019-12-24 11:20:05,373 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 45
2019-12-24 11:20:05,424 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 45
2019-12-24 11:20:05,654 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 45
2019-12-24 11:20:05,655 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 45
2019-12-24 11:20:05,728 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=repl]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 45
2019-12-24 11:20:05,732 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t38) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 46
2019-12-24 11:20:05,771 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t23) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 46
2019-12-24 11:20:05,772 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t30) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 46
2019-12-24 11:20:05,775 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=default]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 45
2019-12-24 11:20:05,910 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t23) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 46
2019-12-24 11:20:05,910 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 46
2019-12-24 11:20:05,910 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t34) [Context=default]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 46
2019-12-24 11:20:05,919 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___protobuf_metadata]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 47
2019-12-24 11:20:05,919 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 47
2019-12-24 11:20:05,955 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t34) [Context=repl]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 46
2019-12-24 11:20:05,955 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) [Context=___hotRodTopologyCache]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 47
2019-12-24 11:20:05,984 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t30) [Context=default]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 47
2019-12-24 11:20:06,069 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) [Context=repl]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 47
2019-12-24 11:20:06,071 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t30) [Context=___script_cache]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 47
2019-12-24 11:20:06,644 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) [Context=org.infinispan.CONFIG]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 47
2019-12-24 13:41:30,183 ERROR [org.jgroups.protocols.UDP] (Timer runner-1,hana11) JGRP000029: hana11: failed sending message to cluster (39 bytes): java.io.IOException: Invalid argument (sendto failed), headers: FD_ALL: heartbeat, TP: [cluster_name=cluster]
2019-12-24 13:41:36,665 ERROR [org.jgroups.protocols.UDP] (Timer runner-1,hana11) JGRP000029: hana11: failed sending message to hana12 (75 bytes): java.io.IOException: Invalid argument (sendto failed), headers: VERIFY_SUSPECT: [VERIFY_SUSPECT: ARE_YOU_DEAD], TP: [cluster_name=cluster]
2019-12-24 13:41:36,666 ERROR [org.jgroups.protocols.UDP] (Timer runner-1,hana11) JGRP000029: hana11: failed sending message to cluster (39 bytes): java.io.IOException: Invalid argument (sendto failed), headers: FD_ALL: heartbeat, TP: [cluster_name=cluster]
2019-12-24 13:41:39,382 ERROR [org.jgroups.protocols.UDP] (Timer runner-1,hana11) JGRP000029: hana11: failed sending message to hana12 (75 bytes): java.io.IOException: Invalid argument (sendto failed), headers: VERIFY_SUSPECT: [VERIFY_SUSPECT: ARE_YOU_DEAD], TP: [cluster_name=cluster]
2019-12-24 13:41:39,396 ERROR [org.jgroups.protocols.UDP] (Timer runner-1,hana11) JGRP000029: hana11: failed sending message to cluster (39 bytes): java.io.IOException: Invalid argument (sendto failed), headers: FD_ALL: heartbeat, TP: [cluster_name=cluster]
2019-12-24 13:41:49,177 INFO  [org.infinispan.CLUSTER] (VERIFY_SUSPECT.TimerThread-127,hana11) ISPN000094: Received new cluster view for channel cluster: [hana11|19] (1) [hana11]
2019-12-24 13:41:50,336 INFO  [org.infinispan.CLUSTER] (VERIFY_SUSPECT.TimerThread-127,hana11) ISPN100001: Node hana12 left the cluster
2019-12-24 13:41:53,684 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___hotRodTopologyCache]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 13:41:56,121 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___hotRodTopologyCache]ISPN100008: Updating cache members list [hana11], topology id 48
2019-12-24 13:41:56,412 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=default]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 13:41:56,622 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=default]ISPN100008: Updating cache members list [hana11], topology id 48
2019-12-24 13:41:58,512 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___protobuf_metadata]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 13:41:58,592 WARN  [org.jgroups.protocols.pbcast.NAKACK2] (jgroups-119,hana11) JGRP000011: hana11: dropped message batch from non-member hana12 (view=[hana11|19] (1) [hana11])
2019-12-24 13:41:58,912 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___protobuf_metadata]ISPN100008: Updating cache members list [hana11], topology id 48
2019-12-24 13:41:59,090 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=org.infinispan.CONFIG]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 13:41:59,136 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=org.infinispan.CONFIG]ISPN100008: Updating cache members list [hana11], topology id 48
2019-12-24 13:42:00,153 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=repl]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 13:42:00,331 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=repl]ISPN100008: Updating cache members list [hana11], topology id 48
2019-12-24 13:42:00,997 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___script_cache]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 13:42:01,239 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___script_cache]ISPN100008: Updating cache members list [hana11], topology id 48
2019-12-24 13:42:01,933 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=HANA_CACHE]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 13:42:01,962 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=HANA_CACHE]ISPN100008: Updating cache members list [hana11], topology id 48
2019-12-24 13:42:02,362 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 13:42:02,508 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100008: Updating cache members list [hana11], topology id 48
2019-12-24 13:42:34,781 INFO  [org.infinispan.CLUSTER] (jgroups-126,hana11) ISPN000093: Received new, MERGED cluster view for channel cluster: MergeView::[hana11|20] (2) [hana11, hana12], 2 subgroups: [hana11|19] (1) [hana11], [hana12|19] (1) [hana12]
2019-12-24 13:42:35,322 INFO  [org.infinispan.CLUSTER] (jgroups-126,hana11) ISPN100000: Node hana12 joined the cluster
2019-12-24 13:42:36,162 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t185) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=48, phase=NO_REBALANCE, rebalanceId=18, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana11: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 13:42:36,162 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t186) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=48, phase=NO_REBALANCE, rebalanceId=18, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana11: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 13:42:36,162 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t166) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=48, phase=NO_REBALANCE, rebalanceId=18, currentCH=DefaultConsistentHash{ns=256, owners = (1)[hana11: 256+0]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 13:42:36,241 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t185) [Context=___hotRodTopologyCache]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 50
2019-12-24 13:42:36,242 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t186) [Context=___protobuf_metadata]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 50
2019-12-24 13:42:36,241 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t166) [Context=default]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 50
2019-12-24 13:42:36,462 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t186) [Context=___protobuf_metadata]ISPN100008: Updating cache members list [hana12], topology id 51
2019-12-24 13:42:36,618 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t166) [Context=default]ISPN100008: Updating cache members list [hana12], topology id 51
2019-12-24 13:42:36,619 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t185) [Context=___hotRodTopologyCache]ISPN100008: Updating cache members list [hana12], topology id 51
2019-12-24 13:42:37,078 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t186) [Context=___protobuf_metadata]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 52
2019-12-24 13:42:37,211 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t166) [Context=default]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 52
2019-12-24 13:42:37,239 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t185) [Context=___hotRodTopologyCache]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 52
2019-12-24 13:42:37,413 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t166) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=48, phase=NO_REBALANCE, rebalanceId=18, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana11: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 13:42:37,451 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t186) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=48, phase=NO_REBALANCE, rebalanceId=18, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana11: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 13:42:37,575 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t166) [Context=org.infinispan.CONFIG]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 50
2019-12-24 13:42:37,576 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t186) [Context=repl]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 50
2019-12-24 13:42:37,741 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t166) [Context=org.infinispan.CONFIG]ISPN100008: Updating cache members list [hana12], topology id 51
2019-12-24 13:42:37,741 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t186) [Context=repl]ISPN100008: Updating cache members list [hana12], topology id 51
2019-12-24 13:42:38,143 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t185) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=48, phase=NO_REBALANCE, rebalanceId=18, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana11: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 13:42:38,345 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t185) [Context=___script_cache]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 50
2019-12-24 13:42:38,338 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t186) [Context=repl]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 52
2019-12-24 13:42:38,346 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t166) [Context=org.infinispan.CONFIG]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 52
2019-12-24 13:42:38,348 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t166) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=48, phase=NO_REBALANCE, rebalanceId=18, currentCH=DefaultConsistentHash{ns=20, owners = (1)[hana11: 20+0]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 13:42:38,348 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t186) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=48, phase=NO_REBALANCE, rebalanceId=18, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana11: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 13:42:38,442 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t186) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 50
2019-12-24 13:42:39,003 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t166) [Context=HANA_CACHE]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 50
2019-12-24 13:42:39,168 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t186) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100008: Updating cache members list [hana12], topology id 51
2019-12-24 13:42:39,181 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t185) [Context=___script_cache]ISPN100008: Updating cache members list [hana12], topology id 51
2019-12-24 13:42:39,466 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t185) [Context=___script_cache]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 52
2019-12-24 13:42:39,802 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t166) [Context=HANA_CACHE]ISPN100008: Updating cache members list [hana12], topology id 51
2019-12-24 13:42:39,803 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t166) [Context=HANA_CACHE]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 52
2019-12-24 13:42:40,544 WARN  [org.infinispan.expiration.impl.ClusterExpirationManager] (pool-10-thread-1) ISPN000026: Caught exception purging data container!: java.lang.IllegalArgumentException: Node hana11 is not a member
	at org.infinispan.distribution.ch.impl.DefaultConsistentHash.getPrimarySegmentsForOwner(DefaultConsistentHash.java:128)
	at org.infinispan.distribution.group.impl.PartitionerConsistentHash.getPrimarySegmentsForOwner(PartitionerConsistentHash.java:76)
	at org.infinispan.expiration.impl.ClusterExpirationManager.purgeInMemoryContents(ClusterExpirationManager.java:119)
	at org.infinispan.expiration.impl.ClusterExpirationManager.processExpiration(ClusterExpirationManager.java:94)
	at org.infinispan.expiration.impl.ExpirationManagerImpl$ScheduledTask.run(ExpirationManagerImpl.java:245)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-12-24 13:42:40,915 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t186) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 52
2019-12-24 13:42:41,708 WARN  [org.infinispan.expiration.impl.ClusterExpirationManager] (pool-10-thread-1) ISPN000026: Caught exception purging data container!: java.lang.IllegalArgumentException: Node hana11 is not a member
	at org.infinispan.distribution.ch.impl.DefaultConsistentHash.getPrimarySegmentsForOwner(DefaultConsistentHash.java:128)
	at org.infinispan.distribution.group.impl.PartitionerConsistentHash.getPrimarySegmentsForOwner(PartitionerConsistentHash.java:76)
	at org.infinispan.expiration.impl.ClusterExpirationManager.purgeInMemoryContents(ClusterExpirationManager.java:119)
	at org.infinispan.expiration.impl.ClusterExpirationManager.processExpiration(ClusterExpirationManager.java:94)
	at org.infinispan.expiration.impl.ExpirationManagerImpl$ScheduledTask.run(ExpirationManagerImpl.java:245)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-12-24 13:42:43,642 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 53
2019-12-24 13:42:43,550 WARN  [org.infinispan.expiration.impl.ClusterExpirationManager] (pool-10-thread-1) ISPN000026: Caught exception purging data container!: java.lang.IllegalArgumentException: Node hana11 is not a member
	at org.infinispan.distribution.ch.impl.DefaultConsistentHash.getPrimarySegmentsForOwner(DefaultConsistentHash.java:128)
	at org.infinispan.distribution.group.impl.PartitionerConsistentHash.getPrimarySegmentsForOwner(PartitionerConsistentHash.java:76)
	at org.infinispan.expiration.impl.ClusterExpirationManager.purgeInMemoryContents(ClusterExpirationManager.java:119)
	at org.infinispan.expiration.impl.ClusterExpirationManager.processExpiration(ClusterExpirationManager.java:94)
	at org.infinispan.expiration.impl.ExpirationManagerImpl$ScheduledTask.run(ExpirationManagerImpl.java:245)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-12-24 13:42:44,006 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 53
2019-12-24 13:42:44,471 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 53
2019-12-24 13:42:44,471 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 53
2019-12-24 13:42:44,496 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=repl]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 53
2019-12-24 13:42:44,497 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 53
2019-12-24 13:42:44,598 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 53
2019-12-24 13:42:44,598 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=default]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 53
2019-12-24 13:42:44,760 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t43) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 54
2019-12-24 13:42:44,887 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 54
2019-12-24 13:42:45,312 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t45) [Context=HANA_CACHE]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 55
2019-12-24 13:42:45,629 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t39) [Context=repl]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 54
2019-12-24 13:42:45,626 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 54
2019-12-24 13:42:45,629 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t40) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 54
2019-12-24 13:42:45,140 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t43) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 54
2019-12-24 13:42:45,386 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t46) [Context=___protobuf_metadata]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 55
2019-12-24 13:42:45,865 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t44) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 54
2019-12-24 13:42:46,012 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) [Context=default]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 54
2019-12-24 13:42:46,056 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t39) [Context=repl]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 55
2019-12-24 13:42:47,027 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 55
2019-12-24 13:42:47,124 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t45) [Context=___hotRodTopologyCache]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 55
2019-12-24 13:42:47,111 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t40) [Context=org.infinispan.CONFIG]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 55
2019-12-24 13:42:47,555 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=default]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 55
2019-12-24 13:42:48,707 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) [Context=___script_cache]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 55
2019-12-24 14:31:05,446 INFO  [org.infinispan.CLUSTER] (VERIFY_SUSPECT.TimerThread-153,hana11) ISPN000094: Received new cluster view for channel cluster: [hana11|21] (1) [hana11]
2019-12-24 14:31:08,590 INFO  [org.infinispan.CLUSTER] (VERIFY_SUSPECT.TimerThread-153,hana11) ISPN100001: Node hana12 left the cluster
2019-12-24 14:31:11,808 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___hotRodTopologyCache]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 14:31:13,250 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___hotRodTopologyCache]ISPN100008: Updating cache members list [hana11], topology id 56
2019-12-24 14:31:14,696 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=default]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 14:31:15,090 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=default]ISPN100008: Updating cache members list [hana11], topology id 56
2019-12-24 14:31:16,617 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___protobuf_metadata]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 14:31:17,523 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___protobuf_metadata]ISPN100008: Updating cache members list [hana11], topology id 56
2019-12-24 14:31:43,627 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=org.infinispan.CONFIG]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 14:31:43,834 WARN  [org.jgroups.protocols.pbcast.NAKACK2] (jgroups-154,hana11) JGRP000011: hana11: dropped message batch from non-member hana12 (view=[hana11|21] (1) [hana11])
2019-12-24 14:31:43,868 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=org.infinispan.CONFIG]ISPN100008: Updating cache members list [hana11], topology id 56
2019-12-24 14:31:44,440 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=repl]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 14:31:44,540 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=repl]ISPN100008: Updating cache members list [hana11], topology id 56
2019-12-24 14:31:44,766 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___script_cache]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 14:31:45,096 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___script_cache]ISPN100008: Updating cache members list [hana11], topology id 56
2019-12-24 14:31:45,418 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=HANA_CACHE]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 14:31:45,507 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=HANA_CACHE]ISPN100008: Updating cache members list [hana11], topology id 56
2019-12-24 14:31:45,699 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 14:31:45,877 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100008: Updating cache members list [hana11], topology id 56
2019-12-24 14:31:50,693 INFO  [org.infinispan.CLUSTER] (jgroups-162,hana11) ISPN000093: Received new, MERGED cluster view for channel cluster: MergeView::[hana11|23] (2) [hana11, hana12], 2 subgroups: [hana11|21] (1) [hana11], [hana12|22] (1) [hana12]
2019-12-24 14:31:50,704 INFO  [org.infinispan.CLUSTER] (jgroups-162,hana11) ISPN100000: Node hana12 joined the cluster
2019-12-24 14:31:52,388 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t194) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=56, phase=NO_REBALANCE, rebalanceId=21, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana11: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 14:31:52,625 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t244) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=56, phase=NO_REBALANCE, rebalanceId=21, currentCH=DefaultConsistentHash{ns=256, owners = (1)[hana11: 256+0]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 14:31:52,562 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t194) [Context=___hotRodTopologyCache]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 58
2019-12-24 14:31:52,728 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t244) [Context=default]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 58
2019-12-24 14:31:52,790 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t245) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=56, phase=NO_REBALANCE, rebalanceId=21, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana11: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 14:31:52,879 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t245) [Context=___protobuf_metadata]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 58
2019-12-24 14:31:53,008 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t194) [Context=___hotRodTopologyCache]ISPN100008: Updating cache members list [hana12], topology id 59
2019-12-24 14:31:53,289 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t244) [Context=default]ISPN100008: Updating cache members list [hana12], topology id 59
2019-12-24 14:31:53,735 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t245) [Context=___protobuf_metadata]ISPN100008: Updating cache members list [hana12], topology id 59
2019-12-24 14:31:54,388 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t244) [Context=default]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 60
2019-12-24 14:31:54,449 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t194) [Context=___hotRodTopologyCache]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 60
2019-12-24 14:31:54,619 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t245) [Context=___protobuf_metadata]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 60
2019-12-24 14:31:54,992 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t245) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=56, phase=NO_REBALANCE, rebalanceId=21, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana11: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 14:31:54,992 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t245) [Context=repl]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 58
2019-12-24 14:31:54,667 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t194) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=56, phase=NO_REBALANCE, rebalanceId=21, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana11: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 14:31:55,064 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t244) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=56, phase=NO_REBALANCE, rebalanceId=21, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana11: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 14:31:55,064 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t244) [Context=___script_cache]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 58
2019-12-24 14:31:55,310 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t194) [Context=org.infinispan.CONFIG]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 58
2019-12-24 14:31:55,876 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t194) [Context=org.infinispan.CONFIG]ISPN100008: Updating cache members list [hana12], topology id 59
2019-12-24 14:31:56,566 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t245) [Context=repl]ISPN100008: Updating cache members list [hana12], topology id 59
2019-12-24 14:31:56,581 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t194) [Context=org.infinispan.CONFIG]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 60
2019-12-24 14:31:56,600 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t194) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=56, phase=NO_REBALANCE, rebalanceId=21, currentCH=DefaultConsistentHash{ns=20, owners = (1)[hana11: 20+0]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 14:31:56,601 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t194) [Context=HANA_CACHE]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 58
2019-12-24 14:31:56,810 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t194) [Context=HANA_CACHE]ISPN100008: Updating cache members list [hana12], topology id 59
2019-12-24 14:31:56,978 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t194) [Context=HANA_CACHE]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 60
2019-12-24 14:31:57,033 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t194) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=56, phase=NO_REBALANCE, rebalanceId=21, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana11: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 14:31:57,124 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t194) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 58
2019-12-24 14:31:56,000 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t244) [Context=___script_cache]ISPN100008: Updating cache members list [hana12], topology id 59
2019-12-24 14:31:57,162 WARN  [org.infinispan.expiration.impl.ClusterExpirationManager] (pool-10-thread-1) ISPN000026: Caught exception purging data container!: java.lang.IllegalArgumentException: Node hana11 is not a member
	at org.infinispan.distribution.ch.impl.DefaultConsistentHash.getPrimarySegmentsForOwner(DefaultConsistentHash.java:128)
	at org.infinispan.distribution.group.impl.PartitionerConsistentHash.getPrimarySegmentsForOwner(PartitionerConsistentHash.java:76)
	at org.infinispan.expiration.impl.ClusterExpirationManager.purgeInMemoryContents(ClusterExpirationManager.java:119)
	at org.infinispan.expiration.impl.ClusterExpirationManager.processExpiration(ClusterExpirationManager.java:94)
	at org.infinispan.expiration.impl.ExpirationManagerImpl$ScheduledTask.run(ExpirationManagerImpl.java:245)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-12-24 14:31:57,442 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t244) [Context=___script_cache]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 60
2019-12-24 14:31:57,443 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t194) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100008: Updating cache members list [hana12], topology id 59
2019-12-24 14:31:57,780 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t194) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 60
2019-12-24 14:31:58,004 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 61
2019-12-24 14:31:58,142 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t245) [Context=repl]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 60
2019-12-24 14:31:58,681 WARN  [org.infinispan.expiration.impl.ClusterExpirationManager] (pool-10-thread-1) ISPN000026: Caught exception purging data container!: java.lang.IllegalArgumentException: Node hana11 is not a member
	at org.infinispan.distribution.ch.impl.DefaultConsistentHash.getPrimarySegmentsForOwner(DefaultConsistentHash.java:128)
	at org.infinispan.distribution.group.impl.PartitionerConsistentHash.getPrimarySegmentsForOwner(PartitionerConsistentHash.java:76)
	at org.infinispan.expiration.impl.ClusterExpirationManager.purgeInMemoryContents(ClusterExpirationManager.java:119)
	at org.infinispan.expiration.impl.ClusterExpirationManager.processExpiration(ClusterExpirationManager.java:94)
	at org.infinispan.expiration.impl.ExpirationManagerImpl$ScheduledTask.run(ExpirationManagerImpl.java:245)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-12-24 14:31:59,411 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 61
2019-12-24 14:31:59,412 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 61
2019-12-24 14:32:00,572 WARN  [org.infinispan.expiration.impl.ClusterExpirationManager] (pool-10-thread-1) ISPN000026: Caught exception purging data container!: java.lang.IllegalArgumentException: Node hana11 is not a member
	at org.infinispan.distribution.ch.impl.DefaultConsistentHash.getPrimarySegmentsForOwner(DefaultConsistentHash.java:128)
	at org.infinispan.distribution.group.impl.PartitionerConsistentHash.getPrimarySegmentsForOwner(PartitionerConsistentHash.java:76)
	at org.infinispan.expiration.impl.ClusterExpirationManager.purgeInMemoryContents(ClusterExpirationManager.java:119)
	at org.infinispan.expiration.impl.ClusterExpirationManager.processExpiration(ClusterExpirationManager.java:94)
	at org.infinispan.expiration.impl.ExpirationManagerImpl$ScheduledTask.run(ExpirationManagerImpl.java:245)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-12-24 14:32:00,592 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t50) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 62
2019-12-24 14:32:00,712 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t52) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 62
2019-12-24 14:32:00,725 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=default]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 61
2019-12-24 14:32:00,728 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 61
2019-12-24 14:32:00,774 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 61
2019-12-24 14:32:01,057 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 61
2019-12-24 14:32:01,194 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=repl]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 61
2019-12-24 14:32:01,297 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t49) [Context=___protobuf_metadata]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 63
2019-12-24 14:32:01,302 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 62
2019-12-24 14:32:01,563 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t50) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 62
2019-12-24 14:32:01,573 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t52) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 62
2019-12-24 14:32:01,574 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t54) [Context=org.infinispan.CONFIG]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 63
2019-12-24 14:32:01,588 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) [Context=repl]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 62
2019-12-24 14:32:01,679 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t51) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 62
2019-12-24 14:32:01,679 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t48) [Context=default]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 62
2019-12-24 14:32:01,777 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t56) [Context=HANA_CACHE]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 63
2019-12-24 14:32:01,939 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t49) [Context=___script_cache]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 63
2019-12-24 14:32:01,939 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t52) [Context=___hotRodTopologyCache]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 63
2019-12-24 14:32:02,241 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 63
2019-12-24 14:32:02,248 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t48) [Context=repl]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 63
2019-12-24 14:32:02,363 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t56) [Context=default]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 63
2019-12-24 14:57:38,933 INFO  [org.infinispan.CLUSTER] (VERIFY_SUSPECT.TimerThread-178,hana11) ISPN000094: Received new cluster view for channel cluster: [hana11|24] (1) [hana11]
2019-12-24 14:57:48,751 INFO  [org.infinispan.CLUSTER] (VERIFY_SUSPECT.TimerThread-178,hana11) ISPN100001: Node hana12 left the cluster
2019-12-24 14:58:03,538 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___hotRodTopologyCache]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 14:58:05,995 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___hotRodTopologyCache]ISPN100008: Updating cache members list [hana11], topology id 64
2019-12-24 14:58:08,994 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=default]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 14:58:09,136 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=default]ISPN100008: Updating cache members list [hana11], topology id 64
2019-12-24 14:58:12,517 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___protobuf_metadata]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 14:58:14,399 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___protobuf_metadata]ISPN100008: Updating cache members list [hana11], topology id 64
2019-12-24 14:58:13,702 WARN  [org.jgroups.protocols.pbcast.NAKACK2] (jgroups-184,hana11) JGRP000011: hana11: dropped message batch from non-member hana12 (view=[hana11|24] (1) [hana11])
2019-12-24 14:58:15,827 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=org.infinispan.CONFIG]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 14:58:18,000 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=org.infinispan.CONFIG]ISPN100008: Updating cache members list [hana11], topology id 64
2019-12-24 14:58:18,801 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=repl]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 14:58:19,185 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=repl]ISPN100008: Updating cache members list [hana11], topology id 64
2019-12-24 14:58:20,356 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___script_cache]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 14:58:20,996 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___script_cache]ISPN100008: Updating cache members list [hana11], topology id 64
2019-12-24 14:58:21,490 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=HANA_CACHE]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 14:58:21,840 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=HANA_CACHE]ISPN100008: Updating cache members list [hana11], topology id 64
2019-12-24 14:58:23,256 WARN  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN000314: Lost at least half of the stable members, possible split brain causing data inconsistency. Current members are [hana11], lost members are [hana12], stable members are [hana12, hana11]
2019-12-24 14:58:23,796 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100008: Updating cache members list [hana11], topology id 64
2019-12-24 14:59:13,313 INFO  [org.infinispan.CLUSTER] (jgroups-186,hana11) ISPN000093: Received new, MERGED cluster view for channel cluster: MergeView::[hana11|25] (2) [hana11, hana12], 2 subgroups: [hana11|24] (1) [hana11], [hana12|24] (1) [hana12]
2019-12-24 14:59:14,101 INFO  [org.infinispan.CLUSTER] (jgroups-186,hana11) ISPN100000: Node hana12 joined the cluster
2019-12-24 14:59:16,310 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t255) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=64, phase=NO_REBALANCE, rebalanceId=24, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana11: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 14:59:16,370 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t255) [Context=___hotRodTopologyCache]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 66
2019-12-24 14:59:16,410 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t303) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=64, phase=NO_REBALANCE, rebalanceId=24, currentCH=DefaultConsistentHash{ns=256, owners = (1)[hana11: 256+0]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 14:59:16,489 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t303) [Context=default]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 66
2019-12-24 14:59:16,518 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t255) [Context=___hotRodTopologyCache]ISPN100008: Updating cache members list [hana12], topology id 67
2019-12-24 14:59:16,660 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t255) [Context=___hotRodTopologyCache]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 68
2019-12-24 14:59:16,903 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t255) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=64, phase=NO_REBALANCE, rebalanceId=24, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana11: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 14:59:16,912 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t255) [Context=org.infinispan.CONFIG]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 66
2019-12-24 14:59:17,657 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t303) [Context=default]ISPN100008: Updating cache members list [hana12], topology id 67
2019-12-24 14:59:16,911 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t304) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=64, phase=NO_REBALANCE, rebalanceId=24, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana11: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 14:59:18,188 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t304) [Context=___protobuf_metadata]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 66
2019-12-24 14:59:18,686 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t255) [Context=org.infinispan.CONFIG]ISPN100008: Updating cache members list [hana12], topology id 67
2019-12-24 14:59:19,280 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t303) [Context=default]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 68
2019-12-24 14:59:20,055 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t304) [Context=___protobuf_metadata]ISPN100008: Updating cache members list [hana12], topology id 67
2019-12-24 14:59:20,331 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t303) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=64, phase=NO_REBALANCE, rebalanceId=24, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana11: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 14:59:20,467 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t303) [Context=repl]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 66
2019-12-24 14:59:21,879 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t304) [Context=___protobuf_metadata]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 68
2019-12-24 14:59:25,372 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t255) [Context=org.infinispan.CONFIG]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 68
2019-12-24 14:59:26,690 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t303) [Context=repl]ISPN100008: Updating cache members list [hana12], topology id 67
2019-12-24 14:59:26,834 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t304) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=64, phase=NO_REBALANCE, rebalanceId=24, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana11: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 14:59:29,183 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t255) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=64, phase=NO_REBALANCE, rebalanceId=24, currentCH=DefaultConsistentHash{ns=20, owners = (1)[hana11: 20+0]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 14:59:29,377 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t304) [Context=___script_cache]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 66
2019-12-24 14:59:29,419 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t255) [Context=HANA_CACHE]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 66
2019-12-24 14:59:30,203 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t255) [Context=HANA_CACHE]ISPN100008: Updating cache members list [hana12], topology id 67
2019-12-24 14:59:30,205 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t255) [Context=HANA_CACHE]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 68
2019-12-24 14:59:30,207 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t255) ISPN000517: Ignoring cache topology from [hana11] during merge: CacheTopology{id=64, phase=NO_REBALANCE, rebalanceId=24, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana11: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana11], persistentUUIDs=[215315b7-c0f8-4253-932c-a36094e68630]}
2019-12-24 14:59:30,207 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t255) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100007: After merge (or coordinator change), recovered members [hana12] with topology id 66
2019-12-24 14:59:30,209 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t255) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100008: Updating cache members list [hana12], topology id 67
2019-12-24 14:59:29,896 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t303) [Context=repl]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 68
2019-12-24 14:59:30,576 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t255) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 68
2019-12-24 14:59:30,431 WARN  [org.infinispan.expiration.impl.ClusterExpirationManager] (pool-10-thread-1) ISPN000026: Caught exception purging data container!: java.lang.IllegalArgumentException: Node hana11 is not a member
	at org.infinispan.distribution.ch.impl.DefaultConsistentHash.getPrimarySegmentsForOwner(DefaultConsistentHash.java:128)
	at org.infinispan.distribution.group.impl.PartitionerConsistentHash.getPrimarySegmentsForOwner(PartitionerConsistentHash.java:76)
	at org.infinispan.expiration.impl.ClusterExpirationManager.purgeInMemoryContents(ClusterExpirationManager.java:119)
	at org.infinispan.expiration.impl.ClusterExpirationManager.processExpiration(ClusterExpirationManager.java:94)
	at org.infinispan.expiration.impl.ExpirationManagerImpl$ScheduledTask.run(ExpirationManagerImpl.java:245)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-12-24 14:59:31,642 WARN  [org.infinispan.expiration.impl.ClusterExpirationManager] (pool-10-thread-1) ISPN000026: Caught exception purging data container!: java.lang.IllegalArgumentException: Node hana11 is not a member
	at org.infinispan.distribution.ch.impl.DefaultConsistentHash.getPrimarySegmentsForOwner(DefaultConsistentHash.java:128)
	at org.infinispan.distribution.group.impl.PartitionerConsistentHash.getPrimarySegmentsForOwner(PartitionerConsistentHash.java:76)
	at org.infinispan.expiration.impl.ClusterExpirationManager.purgeInMemoryContents(ClusterExpirationManager.java:119)
	at org.infinispan.expiration.impl.ClusterExpirationManager.processExpiration(ClusterExpirationManager.java:94)
	at org.infinispan.expiration.impl.ExpirationManagerImpl$ScheduledTask.run(ExpirationManagerImpl.java:245)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-12-24 14:59:30,763 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t304) [Context=___script_cache]ISPN100008: Updating cache members list [hana12], topology id 67
2019-12-24 14:59:32,610 WARN  [org.infinispan.expiration.impl.ClusterExpirationManager] (pool-10-thread-1) ISPN000026: Caught exception purging data container!: java.lang.IllegalArgumentException: The node is not a member : hana11
	at org.infinispan.distribution.ch.impl.ReplicatedConsistentHash.getPrimarySegmentsForOwner(ReplicatedConsistentHash.java:159)
	at org.infinispan.distribution.group.impl.PartitionerConsistentHash.getPrimarySegmentsForOwner(PartitionerConsistentHash.java:76)
	at org.infinispan.expiration.impl.ClusterExpirationManager.purgeInMemoryContents(ClusterExpirationManager.java:119)
	at org.infinispan.expiration.impl.ClusterExpirationManager.processExpiration(ClusterExpirationManager.java:94)
	at org.infinispan.expiration.impl.ExpirationManagerImpl$ScheduledTask.run(ExpirationManagerImpl.java:245)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-12-24 14:59:33,221 WARN  [org.infinispan.expiration.impl.ClusterExpirationManager] (pool-10-thread-1) ISPN000026: Caught exception purging data container!: java.lang.IllegalArgumentException: The node is not a member : hana11
	at org.infinispan.distribution.ch.impl.ReplicatedConsistentHash.getPrimarySegmentsForOwner(ReplicatedConsistentHash.java:159)
	at org.infinispan.distribution.group.impl.PartitionerConsistentHash.getPrimarySegmentsForOwner(PartitionerConsistentHash.java:76)
	at org.infinispan.expiration.impl.ClusterExpirationManager.purgeInMemoryContents(ClusterExpirationManager.java:119)
	at org.infinispan.expiration.impl.ClusterExpirationManager.processExpiration(ClusterExpirationManager.java:94)
	at org.infinispan.expiration.impl.ExpirationManagerImpl$ScheduledTask.run(ExpirationManagerImpl.java:245)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-12-24 14:59:33,420 WARN  [org.infinispan.expiration.impl.ClusterExpirationManager] (pool-10-thread-1) ISPN000026: Caught exception purging data container!: java.lang.IllegalArgumentException: Node hana11 is not a member
	at org.infinispan.distribution.ch.impl.DefaultConsistentHash.getPrimarySegmentsForOwner(DefaultConsistentHash.java:128)
	at org.infinispan.distribution.group.impl.PartitionerConsistentHash.getPrimarySegmentsForOwner(PartitionerConsistentHash.java:76)
	at org.infinispan.expiration.impl.ClusterExpirationManager.purgeInMemoryContents(ClusterExpirationManager.java:119)
	at org.infinispan.expiration.impl.ClusterExpirationManager.processExpiration(ClusterExpirationManager.java:94)
	at org.infinispan.expiration.impl.ExpirationManagerImpl$ScheduledTask.run(ExpirationManagerImpl.java:245)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-12-24 14:59:34,236 ERROR [org.infinispan.interceptors.impl.InvocationContextInterceptor] (timeout-thread--p3-t1) ISPN000136: Error executing command PutKeyValueCommand on Cache '___hotRodTopologyCache', writing keys [hana11]: org.infinispan.util.concurrent.TimeoutException: ISPN000476: Timed out waiting for responses for request 301 from hana12
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onTimeout(SingleTargetRequest.java:65)
	at org.infinispan.remoting.transport.AbstractRequest.call(AbstractRequest.java:87)
	at org.infinispan.remoting.transport.AbstractRequest.call(AbstractRequest.java:22)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-12-24 14:59:35,805 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t304) [Context=___script_cache]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 68
2019-12-24 14:59:35,516 WARN  [org.infinispan.expiration.impl.ClusterExpirationManager] (pool-10-thread-1) ISPN000026: Caught exception purging data container!: java.lang.IllegalArgumentException: Node hana11 is not a member
	at org.infinispan.distribution.ch.impl.DefaultConsistentHash.getPrimarySegmentsForOwner(DefaultConsistentHash.java:128)
	at org.infinispan.distribution.group.impl.PartitionerConsistentHash.getPrimarySegmentsForOwner(PartitionerConsistentHash.java:76)
	at org.infinispan.expiration.impl.ClusterExpirationManager.purgeInMemoryContents(ClusterExpirationManager.java:119)
	at org.infinispan.expiration.impl.ClusterExpirationManager.processExpiration(ClusterExpirationManager.java:94)
	at org.infinispan.expiration.impl.ExpirationManagerImpl$ScheduledTask.run(ExpirationManagerImpl.java:245)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-12-24 14:59:41,363 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 69
2019-12-24 14:59:41,314 ERROR [org.infinispan.interceptors.impl.InvocationContextInterceptor] (timeout-thread--p3-t1) ISPN000136: Error executing command PutKeyValueCommand on Cache '___hotRodTopologyCache', writing keys [hana11]: org.infinispan.util.concurrent.TimeoutException: ISPN000476: Timed out waiting for responses for request 304 from hana12
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onTimeout(SingleTargetRequest.java:65)
	at org.infinispan.remoting.transport.AbstractRequest.call(AbstractRequest.java:87)
	at org.infinispan.remoting.transport.AbstractRequest.call(AbstractRequest.java:22)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-12-24 14:59:42,129 WARN  [org.infinispan.expiration.impl.ClusterExpirationManager] (pool-10-thread-1) ISPN000026: Caught exception purging data container!: java.lang.IllegalArgumentException: Node hana11 is not a member
	at org.infinispan.distribution.ch.impl.DefaultConsistentHash.getPrimarySegmentsForOwner(DefaultConsistentHash.java:128)
	at org.infinispan.distribution.group.impl.PartitionerConsistentHash.getPrimarySegmentsForOwner(PartitionerConsistentHash.java:76)
	at org.infinispan.expiration.impl.ClusterExpirationManager.purgeInMemoryContents(ClusterExpirationManager.java:119)
	at org.infinispan.expiration.impl.ClusterExpirationManager.processExpiration(ClusterExpirationManager.java:94)
	at org.infinispan.expiration.impl.ExpirationManagerImpl$ScheduledTask.run(ExpirationManagerImpl.java:245)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-12-24 14:59:51,499 INFO  [org.infinispan.CLUSTER] (VERIFY_SUSPECT.TimerThread-195,hana11) ISPN000094: Received new cluster view for channel cluster: [hana11|26] (1) [hana11]
2019-12-24 15:00:23,920 INFO  [org.infinispan.CLUSTER] (VERIFY_SUSPECT.TimerThread-195,hana11) ISPN100001: Node hana12 left the cluster
2019-12-24 15:00:29,042 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=default]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 69
2019-12-24 15:00:29,697 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 69
2019-12-24 15:00:29,732 FATAL [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___hotRodTopologyCache]ISPN000313: Lost data because of abrupt leavers [hana12]
2019-12-24 15:00:34,409 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 69
2019-12-24 15:00:36,726 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 69
2019-12-24 15:00:44,109 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___hotRodTopologyCache]ISPN100008: Updating cache members list [hana11], topology id 70
2019-12-24 15:00:29,042 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 69
2019-12-24 15:00:36,191 WARN  [org.jgroups.protocols.pbcast.NAKACK2] (jgroups-183,hana11) JGRP000011: hana11: dropped message batch from non-member hana12 (view=[hana11|26] (1) [hana11])
2019-12-24 15:00:44,896 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 69
2019-12-24 15:00:46,197 FATAL [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=default]ISPN000313: Lost data because of abrupt leavers [hana12]
2019-12-24 15:00:46,975 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=repl]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 69
2019-12-24 15:00:46,867 INFO  [org.infinispan.CLUSTER] (jgroups-184,hana11) ISPN000093: Received new, MERGED cluster view for channel cluster: MergeView::[hana11|27] (2) [hana11, hana12], 2 subgroups: [hana11|26] (1) [hana11], [hana12|26] (1) [hana12]
2019-12-24 15:00:47,114 INFO  [org.infinispan.CLUSTER] (jgroups-184,hana11) ISPN100000: Node hana12 joined the cluster
2019-12-24 15:00:48,131 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=default]ISPN100008: Updating cache members list [hana11], topology id 70
2019-12-24 15:00:51,129 FATAL [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t330) [Context=default]ISPN000313: Lost data because of abrupt leavers [hana12]
2019-12-24 15:00:51,129 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t361) ISPN000517: Ignoring cache topology from [hana12] during merge: CacheTopology{id=69, phase=NO_REBALANCE, rebalanceId=28, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana12: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana12], persistentUUIDs=[bfe1bf97-2986-4011-9c82-d27ccebf0f7f]}
2019-12-24 15:00:51,129 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t311) ISPN000517: Ignoring cache topology from [hana12] during merge: CacheTopology{id=69, phase=NO_REBALANCE, rebalanceId=28, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana12: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana12], persistentUUIDs=[bfe1bf97-2986-4011-9c82-d27ccebf0f7f]}
2019-12-24 15:00:51,552 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t361) [Context=___hotRodTopologyCache]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 71
2019-12-24 15:00:51,891 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t311) [Context=___protobuf_metadata]ISPN100007: After merge (or coordinator change), recovered members [hana12, hana11] with topology id 70
2019-12-24 15:00:51,986 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t330) [Context=default]ISPN100007: After merge (or coordinator change), recovered members [hana11] with topology id 71
2019-12-24 15:00:52,343 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t361) [Context=___hotRodTopologyCache]ISPN100008: Updating cache members list [hana11], topology id 72
2019-12-24 15:00:53,440 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t330) [Context=default]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 72
2019-12-24 15:00:54,126 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t311) [Context=___protobuf_metadata]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 71
2019-12-24 15:00:53,057 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t361) [Context=___hotRodTopologyCache]ISPN100002: Starting rebalance with members [hana11, hana12], phase READ_OLD_WRITE_ALL, topology id 73
2019-12-24 15:00:55,088 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t361) ISPN000517: Ignoring cache topology from [hana12] during merge: CacheTopology{id=69, phase=NO_REBALANCE, rebalanceId=28, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana12: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana12], persistentUUIDs=[bfe1bf97-2986-4011-9c82-d27ccebf0f7f]}
2019-12-24 15:00:55,261 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t361) [Context=repl]ISPN100007: After merge (or coordinator change), recovered members [hana12, hana11] with topology id 70
2019-12-24 15:00:55,791 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t361) [Context=repl]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 71
2019-12-24 15:00:55,677 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t330) ISPN000517: Ignoring cache topology from [hana12] during merge: CacheTopology{id=69, phase=NO_REBALANCE, rebalanceId=28, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana12: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana12], persistentUUIDs=[bfe1bf97-2986-4011-9c82-d27ccebf0f7f]}
2019-12-24 15:00:56,742 WARN  [org.infinispan.partitionhandling.impl.PreferAvailabilityStrategy] (stateTransferExecutor-thread--p5-t311) ISPN000517: Ignoring cache topology from [hana12] during merge: CacheTopology{id=69, phase=NO_REBALANCE, rebalanceId=28, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[hana12: 256]}, pendingCH=null, unionCH=null, actualMembers=[hana12], persistentUUIDs=[bfe1bf97-2986-4011-9c82-d27ccebf0f7f]}
2019-12-24 15:00:56,894 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t330) [Context=___script_cache]ISPN100007: After merge (or coordinator change), recovered members [hana12, hana11] with topology id 70
2019-12-24 15:00:56,894 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t311) [Context=org.infinispan.CONFIG]ISPN100007: After merge (or coordinator change), recovered members [hana12, hana11] with topology id 70
2019-12-24 15:00:58,073 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t361) [Context=HANA_CACHE]ISPN100007: After merge (or coordinator change), recovered members [hana12, hana11] with topology id 70
2019-12-24 15:00:58,119 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t361) [Context=HANA_CACHE]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 71
2019-12-24 15:00:58,146 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 72
2019-12-24 15:00:59,947 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t361) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100007: After merge (or coordinator change), recovered members [hana12, hana11] with topology id 70
2019-12-24 15:01:00,814 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t56) [Context=repl]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 72
2019-12-24 15:01:00,892 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t330) [Context=___script_cache]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 71
2019-12-24 15:01:01,935 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t56) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 72
2019-12-24 15:01:04,322 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t61) [Context=___protobuf_metadata]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 73
2019-12-24 15:01:04,323 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t361) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 71
2019-12-24 15:01:04,598 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t60) [Context=repl]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 73
2019-12-24 15:01:04,606 INFO  [org.infinispan.CLUSTER] (stateTransferExecutor-thread--p5-t311) [Context=org.infinispan.CONFIG]ISPN100002: Starting rebalance with members [hana12, hana11], phase READ_OLD_WRITE_ALL, topology id 71
2019-12-24 15:01:06,912 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t61) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 72
2019-12-24 15:01:06,786 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t56) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 72
2019-12-24 15:01:07,113 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t62) [Context=___protobuf_metadata]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 74
2019-12-24 15:01:07,113 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t63) [Context=HANA_CACHE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 73
2019-12-24 15:01:07,115 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t60) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 72
2019-12-24 15:01:07,860 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t59) [Context=repl]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 74
2019-12-24 15:01:13,094 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t63) [Context=org.infinispan.CONFIG]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 73
2019-12-24 15:01:13,926 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t56) [Context=___script_cache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 73
2019-12-24 15:01:14,320 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t61) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 74
2019-12-24 15:01:15,530 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t63) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 73
2019-12-24 15:01:16,052 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=org.infinispan.CONFIG]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 74
2019-12-24 15:01:16,902 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t59) [Context=HANA_CACHE]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 74
2019-12-24 15:01:18,129 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=org.infinispan.CLIENT_SERVER_TX_TABLE]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 74
2019-12-24 15:01:18,581 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t63) [Context=default]ISPN100009: Advancing to rebalance phase READ_ALL_WRITE_ALL, topology id 73
2019-12-24 15:01:20,224 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___script_cache]ISPN100010: Finished rebalance with members [hana12, hana11], topology id 74
2019-12-24 15:01:20,466 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___hotRodTopologyCache]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 75
2019-12-24 15:01:23,225 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t63) [Context=___hotRodTopologyCache]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 76
2019-12-24 15:01:24,833 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t63) [Context=default]ISPN100009: Advancing to rebalance phase READ_NEW_WRITE_ALL, topology id 74
2019-12-24 15:01:27,997 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t63) [Context=default]ISPN100010: Finished rebalance with members [hana11, hana12], topology id 75
